---
layout: post
title: 深度學習500問-03-深度學習基礎
categories: Dev
tags: [deep learning]
---

author: [scutan90](https://github.com/scutan90/DeepLearning-500-questions)

> Description:
>
> 深度學習內容相關筆記	

<!-- more -->

# 第三章 深度學習基礎

## 3.1 基本概念

### 3.1.1 神經網絡組成？

神經網絡類型眾多，其中最為重要的是多層感知機。為了詳細地描述神經網絡，我們先從最簡單的神經網絡說起。

**感知機**

多層感知機中的特征神經元模型稱為感知機，由*Frank Rosenblatt*於1957年发明。

簡單的感知機如下圖所示：

![](/public/img/deep-learning-03/3-1.png)

其中$x_1$，$x_2$，$x_3$為感知機的輸入，其輸出為：

$$
output = \left\{
\begin{aligned}
0, \quad if \ \ \sum_i w_i x_i \leqslant threshold \\
1, \quad if \ \ \sum_i w_i x_i > threshold
\end{aligned}
\right.
$$

假如把感知機想象成一個加權投票機制，比如 3 位評委給一個歌手打分，打分分別為$ 4 $分、$1$ 分、$-3 $分，這$ 3$ 位評分的權重分別是 $1、3、2$，則該歌手最終得分為 $4 \times 1 + 1 \times 3 + (-3) \times 2 = 1$ 。按照比賽規則，選取的 $threshold$ 為 $3$，說明只有歌手的綜合評分大於$ 3$ 時，才可順利晉級。對照感知機，該選手被淘汰，因為：

$$
\sum_i w_i x_i < threshold=3, output = 0
$$

用 $-b$  代替 $threshold$，輸出變為：

$$
output = \left\{
\begin{aligned}
0, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b \leqslant 0 \\
1, \quad if \ \ \boldsymbol{w} \cdot \boldsymbol{x} + b > 0
\end{aligned}
\right.
$$

設置合適的  $\boldsymbol{x}$  和  $b$ ，一個簡單的感知機單元的與非門表示如下：

![](/public/img/deep-learning-03/3-2.png)

當輸入為 $0$，$1$ 時，感知機輸出為 $ 0 \times (-2) + 1 \times (-2) + 3 = 1$。

覆雜一些的感知機由簡單的感知機單元組合而成：

![](/public/img/deep-learning-03/3-3.png)

**多層感知機**

多層感知機由感知機推廣而來，最主要的特點是有多個神經元層，因此也叫深度神經網絡。相比於單獨的感知機，多層感知機的第 $ i $ 層的每個神經元和第 $ i-1 $ 層的每個神經元都有連接。

![](/public/img/deep-learning-03/3.1.1.5.png)

輸出層可以不止有$ 1$ 個神經元。隱藏層可以只有$ 1$ 層，也可以有多層。輸出層為多個神經元的神經網絡例如下圖所示：

![](/public/img/deep-learning-03/3.1.1.6.png)


### 3.1.2 神經網絡有哪些常用模型結構？

下圖包含了大部分常用的模型：

![](/public/img/deep-learning-03/3-7.jpg)

### 3.1.3 如何選擇深度學習開发平台？

​	現有的深度學習開源平台主要有 Caffe, PyTorch, MXNet, CNTK, Theano, TensorFlow, Keras, fastai等。那如何選擇一個適合自己的平台呢，下面列出一些衡量做參考。

**參考1：與現有編程平台、技能整合的難易程度**

​	主要是前期積累的開发經驗和資源，比如編程語言，前期數據集存儲格式等。

**參考2: 與相關機器學習、數據處理生態整合的緊密程度**

​	深度學習研究離不開各種數據處理、可視化、統計推斷等軟件包。考慮建模之前，是否具有方便的數據預處理工具？建模之後，是否具有方便的工具進行可視化、統計推斷、數據分析。  

**參考3：對數據量及硬件的要求和支持**

​	深度學習在不同應用場景的數據量是不一樣的，這也就導致我們可能需要考慮分布式計算、多GPU計算的問題。例如，對計算機圖像處理研究的人員往往需要將圖像文件和計算任務分部到多台計算機節點上進行執行。當下每個深度學習平台都在快速发展，每個平台對分布式計算等場景的支持也在不斷演進。

**參考4：深度學習平台的成熟程度**

​	成熟程度的考量是一個比較主觀的考量因素，這些因素可包括：社區的活躍程度；是否容易和開发人員進行交流；當前應用的勢頭。

**參考5：平台利用是否多樣性？**

​	有些平台是專門為深度學習研究和應用進行開发的，有些平台對分布式計算、GPU 等構架都有強大的優化，能否用這些平台/軟件做其他事情？比如有些深度學習軟件是可以用來求解二次型優化；有些深度學習平台很容易被擴展，被運用在強化學習的應用中。

### 3.1.4 為什麽使用深層表示?

1. 深度神經網絡是一種特征遞進式的學習算法，淺層的神經元直接從輸入數據中學習一些低層次的簡單特征，例如邊緣、紋理等。而深層的特征則基於已學習到的淺層特征繼續學習更高級的特征，從計算機的角度學習深層的語義信息。
2. 深層的網絡隱藏單元數量相對較少，隱藏層數目較多，如果淺層的網絡想要達到同樣的計算結果則需要指數級增長的單元數量才能達到。

### 3.1.5 為什麽深層神經網絡難以訓練？


1. 梯度消失
    	梯度消失是指通過隱藏層從後向前看，梯度會變的越來越小，說明前面層的學習會顯著慢於後面層的學習，所以學習會卡住，除非梯度變大。

    ​	梯度消失的原因受到多種因素影響，例如學習率的大小，網絡參數的初始化，激活函數的邊緣效應等。在深層神經網絡中，每一個神經元計算得到的梯度都會傳遞給前一層，較淺層的神經元接收到的梯度受到之前所有層梯度的影響。如果計算得到的梯度值非常小，隨著層數增多，求出的梯度更新信息將會以指數形式衰減，就會发生梯度消失。下圖是不同隱含層的學習速率：

![](/public/img/deep-learning-03/3-8.png)

2. 梯度爆炸
    	在深度網絡或循環神經網絡（Recurrent Neural Network, RNN）等網絡結構中，梯度可在網絡更新的過程中不斷累積，變成非常大的梯度，導致網絡權重值的大幅更新，使得網絡不穩定；在極端情況下，權重值甚至會溢出，變為$NaN$值，再也無法更新。

3. 權重矩陣的退化導致模型的有效自由度減少。

    ​	參數空間中學習的退化速度減慢，導致減少了模型的有效維數，網絡的可用自由度對學習中梯度範數的貢獻不均衡，隨著相乘矩陣的數量（即網絡深度）的增加，矩陣的乘積變得越來越退化。在有硬飽和邊界的非線性網絡中（例如 ReLU 網絡），隨著深度增加，退化過程會變得越來越快。Duvenaud等人2014年的論文里展示了關於該退化過程的可視化：

![](/public/img/deep-learning-03/3-9.jpg)

隨著深度的增加，輸入空間（左上角所示）會在輸入空間中的每個點處被扭曲成越來越細的單絲，只有一個與細絲正交的方向影響網絡的響應。沿著這個方向，網絡實際上對變化變得非常敏感。

### 3.1.6 深度學習和機器學習有什麽不同？

​	**機器學習**：利用計算機、概率論、統計學等知識，輸入數據，讓計算機學會新知識。機器學習的過程，就是訓練數據去優化目標函數。

​	**深度學習**：是一種特殊的機器學習，具有強大的能力和靈活性。它通過學習將世界表示為嵌套的層次結構，每個表示都與更簡單的特征相關，而抽象的表示則用於計算更抽象的表示。

​	傳統的機器學習需要定義一些手工特征，從而有目的的去提取目標信息， 非常依賴任務的特異性以及設計特征的專家經驗。而深度學習可以從大數據中先學習簡單的特征，並從其逐漸學習到更為覆雜抽象的深層特征，不依賴人工的特征工程，這也是深度學習在大數據時代受歡迎的一大原因。



![](/public/img/deep-learning-03/3.1.6.1.png)

![](/public/img/deep-learning-03/3-11.jpg)

## 3.2 網絡操作與計算

### 3.2.1 前向傳播與反向傳播？

神經網絡的計算主要有兩種：前向傳播（foward propagation, FP）作用於每一層的輸入，通過逐層計算得到輸出結果；反向傳播（backward propagation, BP）作用於網絡的輸出，通過計算梯度由深到淺更新網絡參數。

**前向傳播**

![](/public/img/deep-learning-03/3.2.1.1.png)

假設上一層結點 $ i,j,k,... $ 等一些結點與本層的結點 $ w $ 有連接，那麽結點 $ w $ 的值怎麽算呢？就是通過上一層的 $ i,j,k,... $ 等結點以及對應的連接權值進行加權和運算，最終結果再加上一個偏置項（圖中為了簡單省略了），最後在通過一個非線性函數（即激活函數），如 $ReLu$，$sigmoid$ 等函數，最後得到的結果就是本層結點 $ w $ 的輸出。 

最終不斷的通過這種方法一層層的運算，得到輸出層結果。

**反向傳播**

![](/public/img/deep-learning-03/3.2.1.2.png)

由於我們前向傳播最終得到的結果，以分類為例，最終總是有誤差的，那麽怎麽減少誤差呢，當前應用廣泛的一個算法就是梯度下降算法，但是求梯度就要求偏導數，下面以圖中字母為例講解一下：

設最終誤差為 $ E $且輸出層的激活函數為線性激活函數，對於輸出那麽 $ E $ 對於輸出節點 $ y_l $ 的偏導數是 $ y_l - t_l $，其中 $ t_l $ 是真實值，$ \frac{\partial y_l}{\partial z_l} $ 是指上面提到的激活函數，$ z_l $ 是上面提到的加權和，那麽這一層的 $ E $ 對於 $ z_l $ 的偏導數為 $ \frac{\partial E}{\partial z_l} = \frac{\partial E}{\partial y_l} \frac{\partial y_l}{\partial z_l} $。同理，下一層也是這麽計算，只不過 $ \frac{\partial E}{\partial y_k} $ 計算方法變了，一直反向傳播到輸入層，最後有 $ \frac{\partial E}{\partial x_i} = \frac{\partial E}{\partial y_j} \frac{\partial y_j}{\partial z_j} $，且 $ \frac{\partial z_j}{\partial x_i} = w_i j $。然後調整這些過程中的權值，再不斷進行前向傳播和反向傳播的過程，最終得到一個比較好的結果。

### 3.2.2 如何計算神經網絡的輸出？

![](/public/img/deep-learning-03/3.2.2.1.png)

如上圖，輸入層有三個節點，我們將其依次編號為 1、2、3；隱藏層的 4 個節點，編號依次為 4、5、6、7；最後輸出層的兩個節點編號為 8、9。比如，隱藏層的節點 4，它和輸入層的三個節點 1、2、3 之間都有連接，其連接上的權重分別為是 $ w_{41}, w_{42}, w_{43} $。

為了計算節點 4 的輸出值，我們必須先得到其所有上遊節點（也就是節點 1、2、3）的輸出值。節點 1、2、3 是輸入層的節點，所以，他們的輸出值就是輸入向量本身。按照上圖畫出的對應關系，可以看到節點 1、2、3 的輸出值分別是 $ x_1, x_2, x_3 $。

$$
a_4 = \sigma(w^T \cdot a) = \sigma(w_{41}x_4 + w_{42}x_2 + w_{43}a_3 + w_{4b})
$$

其中 $ w_{4b} $ 是節點 4 的偏置項。

同樣，我們可以繼續計算出節點 5、6、7 的輸出值 $ a_5, a_6, a_7 $。

計算輸出層的節點 8 的輸出值 $ y_1 $：

$$
y_1 = \sigma(w^T \cdot a) = \sigma(w_{84}a_4 + w_{85}a_5 + w_{86}a_6 + w_{87}a_7 + w_{8b})
$$

其中 $ w_{8b} $ 是節點 8 的偏置項。

同理，我們還可以計算出 $ y_2 $。這樣輸出層所有節點的輸出值計算完畢，我們就得到了在輸入向量 $ x_1, x_2, x_3, x_4 $ 時，神經網絡的輸出向量 $ y_1, y_2 $ 。這里我們也看到，輸出向量的維度和輸出層神經元個數相同。

### 3.2.3 如何計算卷積神經網絡輸出值？

假設有一個 5\*5 的圖像，使用一個 3\*3 的 filter 進行卷積，想得到一個 3\*3 的 Feature Map，如下所示：

![](/public/img/deep-learning-03/3.2.3.1.png)

$ x_{i,j} $ 表示圖像第  $ i $ 行第 $ j $ 列元素。$ w_{m,n} $ 表示 filter​ 第 $ m $ 行第 $ n $ 列權重。 $ w_b $ 表示 $filter$ 的偏置項。 表$a_i,_j$示 feature map 第 $ i$ 行第 $ j $ 列元素。 $f$ 表示激活函數，這里以$ ReLU$ 函數為例。

卷積計算公式如下：

$$
a_{i,j} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{i+m, j+n} + w_b )
$$

當步長為 $1$ 時，計算 feature map 元素 $ a_{0,0} $ 如下：

$$
a_{0,0} = f(\sum_{m=0}^2 \sum_{n=0}^2 w_{m,n} x_{0+m, 0+n} + w_b )

= relu(w_{0,0} x_{0,0} + w_{0,1} x_{0,1} + w_{0,2} x_{0,2} + w_{1,0} x_{1,0} + \\w_{1,1} x_{1,1} + w_{1,2} x_{1,2} + w_{2,0} x_{2,0} + w_{2,1} x_{2,1} + w_{2,2} x_{2,2}) \\

= 1 + 0 + 1 + 0 + 1 + 0 + 0 + 0 + 1 \\

= 4
$$

其計算過程圖示如下：

![](/public/img/deep-learning-03/3.2.3.2.png)

以此類推，計算出全部的Feature Map。

![](/public/img/deep-learning-03/3.2.3.4.png)

當步幅為 2 時，Feature Map計算如下

![](/public/img/deep-learning-03/3.2.3.5.png)

注：圖像大小、步幅和卷積後的Feature Map大小是有關系的。它們滿足下面的關系：

$$
W_2 = (W_1 - F + 2P)/S + 1\\
H_2 = (H_1 - F + 2P)/S + 1
$$

​	其中 $ W_2 $， 是卷積後 Feature Map 的寬度；$ W_1 $ 是卷積前圖像的寬度；$ F $ 是 filter 的寬度；$ P $ 是 Zero Padding 數量，Zero Padding 是指在原始圖像周圍補幾圈 $0$，如果 $P$ 的值是 $1$，那麽就補 $1$ 圈 $0$；$S$ 是步幅；$ H_2 $ 卷積後 Feature Map 的高度；$ H_1 $ 是卷積前圖像的寬度。

​	舉例：假設圖像寬度 $ W_1 = 5 $，filter 寬度 $ F=3 $，Zero Padding $ P=0 $，步幅 $ S=2 $，$ Z $ 則

$$
W_2 = (W_1 - F + 2P)/S + 1

= (5-3+0)/2 + 1

= 2
$$

​	說明 Feature Map 寬度是2。同樣，我們也可以計算出 Feature Map 高度也是 2。

如果卷積前的圖像深度為 $ D $，那麽相應的 filter 的深度也必須為 $ D $。深度大於 1 的卷積計算公式：

$$
a_{i,j} = f(\sum_{d=0}^{D-1} \sum_{m=0}^{F-1} \sum_{n=0}^{F-1} w_{d,m,n} x_{d,i+m,j+n} + w_b)
$$

​	其中，$ D $ 是深度；$ F $ 是 filter 的大小；$ w_{d,m,n} $ 表示 filter 的第 $ d $ 層第 $ m $ 行第 $ n $ 列權重；$ a_{d,i,j} $ 表示 feature map 的第 $ d $ 層第 $ i $ 行第 $ j $ 列像素；其它的符號含義前面相同，不再贅述。

​	每個卷積層可以有多個 filter。每個 filter 和原始圖像進行卷積後，都可以得到一個 Feature Map。卷積後 Feature Map 的深度(個數)和卷積層的 filter 個數相同。下面的圖示顯示了包含兩個 filter 的卷積層的計算。 $$7*7*3$$ 輸入，經過兩個 $$3*3*3$$ filter 的卷積(步幅為 $2$)，得到了 $$3*3*2$$ 的輸出。圖中的 Zero padding 是 $1$，也就是在輸入元素的周圍補了一圈 $0$。

![](/public/img/deep-learning-03/3.2.3.6.png)

​	以上就是卷積層的計算方法。這里面體現了局部連接和權值共享：每層神經元只和上一層部分神經元相連(卷積計算規則)，且 filter 的權值對於上一層所有神經元都是一樣的。對於包含兩個 $ 3 * 3 * 3 $ 的 fitler 的卷積層來說，其參數數量僅有 $ (3 * 3 * 3+1) * 2 = 56 $ 個，且參數數量與上一層神經元個數無關。與全連接神經網絡相比，其參數數量大大減少了。

### 3.2.4 如何計算 Pooling 層輸出值輸出值？

​	Pooling 層主要的作用是下采樣，通過去掉 Feature Map 中不重要的樣本，進一步減少參數數量。Pooling 的方法很多，最常用的是 Max Pooling。Max Pooling 實際上就是在 n\*n 的樣本中取最大值，作為采樣後的樣本值。下圖是 2\*2 max pooling：

![](/public/img/deep-learning-03/3.2.4.1.png)

​	除了 Max Pooing 之外，常用的還有 Average Pooling ——取各樣本的平均值。
​	對於深度為 $ D $ 的 Feature Map，各層獨立做 Pooling，因此 Pooling 後的深度仍然為 $ D $。

### 3.2.5 實例理解反向傳播

​	一個典型的三層神經網絡如下所示：

![](/public/img/deep-learning-03/3.2.5.1.png)

​	其中 Layer $ L_1 $ 是輸入層，Layer $ L_2 $ 是隱含層，Layer $ L_3 $ 是輸出層。

​	假設輸入數據集為 $ D={x_1, x_2, ..., x_n} $，輸出數據集為 $ y_1, y_2, ..., y_n $。

​	如果輸入和輸出是一樣，即為自編碼模型。如果原始數據經過映射，會得到不同於輸入的輸出。

假設有如下的網絡層：

![](/public/img/deep-learning-03/3.2.5.2.png)

​	輸入層包含神經元 $ i_1, i_2 $，偏置 $ b_1 $；隱含層包含神經元 $ h_1, h_2 $，偏置 $ b_2 $，輸出層為  $ o_1, o_2 $，$ w_i $ 為層與層之間連接的權重，激活函數為 $sigmoid$ 函數。對以上參數取初始值，如下圖所示：

![](/public/img/deep-learning-03/3.2.5.3.png)

其中：

- 輸入數據 $ i1=0.05, i2 = 0.10 $
- 輸出數據 $ o1=0.01, o2=0.99 $;
- 初始權重 $ w1=0.15, w2=0.20, w3=0.25,w4=0.30, w5=0.40, w6=0.45, w7=0.50, w8=0.55 $
- 目標：給出輸入數據 $ i1,i2 $ ( $0.05$和$0.10$ )，使輸出盡可能與原始輸出 $ o1,o2 $，( $0.01$和$0.99$)接近。

**前向傳播**

1. 輸入層 --> 輸出層

計算神經元 $ h1 $ 的輸入加權和：

$$
net_{h1} = w_1 * i_1 + w_2 * i_2 + b_1 * 1\\

net_{h1} = 0.15 * 0.05 + 0.2 * 0.1 + 0.35 * 1 = 0.3775
$$

神經元 $ h1 $ 的輸出 $ o1 $ ：（此處用到激活函數為 sigmoid 函數）：

$$
out_{h1} = \frac{1}{1 + e^{-net_{h1}}} = \frac{1}{1 + e^{-0.3775}} = 0.593269992
$$

同理，可計算出神經元 $ h2 $ 的輸出 $ o1 $：

$$
out_{h2} = 0.596884378
$$


2. 隱含層-->輸出層：  　　

計算輸出層神經元 $ o1 $ 和 $ o2 $ 的值：

$$
net_{o1} = w_5 * out_{h1} + w_6 * out_{h2} + b_2 * 1
$$

$$
net_{o1} = 0.4 * 0.593269992 + 0.45 * 0.596884378 + 0.6 * 1 = 1.105905967
$$

$$
out_{o1} = \frac{1}{1 + e^{-net_{o1}}} = \frac{1}{1 + e^{1.105905967}} = 0.75136079
$$

這樣前向傳播的過程就結束了，我們得到輸出值為 $ [0.75136079 ,  0.772928465] $，與實際值 $ [0.01 , 0.99] $ 相差還很遠，現在我們對誤差進行反向傳播，更新權值，重新計算輸出。

**反向傳播**

​	1.計算總誤差

總誤差：(這里使用Square Error)

$$
E_{total} = \sum \frac{1}{2}(target - output)^2
$$

但是有兩個輸出，所以分別計算 $ o1 $ 和 $ o2 $ 的誤差，總誤差為兩者之和：

$E_{o1} = \frac{1}{2}(target_{o1} - out_{o1})^2 
= \frac{1}{2}(0.01 - 0.75136507)^2 = 0.274811083$.

$E_{o2} = 0.023560026$.

$E_{total} = E_{o1} + E_{o2} = 0.274811083 + 0.023560026 = 0.298371109$.

​	2.隱含層 --> 輸出層的權值更新：

以權重參數 $ w5 $ 為例，如果我們想知道 $ w5 $ 對整體誤差產生了多少影響，可以用整體誤差對 $ w5 $ 求偏導求出：（鏈式法則）

$$
\frac{\partial E_{total}}{\partial w5} = \frac{\partial E_{total}}{\partial out_{o1}} * \frac{\partial out_{o1}}{\partial net_{o1}} * \frac{\partial net_{o1}}{\partial w5}
$$

下面的圖可以更直觀的看清楚誤差是怎樣反向傳播的：

![](/public/img/deep-learning-03/3.2.5.4.png)

### 3.2.6 神經網絡更“深”有什麽意義？

前提：在一定範圍內。

- 在神經元數量相同的情況下，深層網絡結構具有更大容量，分層組合帶來的是指數級的表達空間，能夠組合成更多不同類型的子結構，這樣可以更容易地學習和表示各種特征。
- 隱藏層增加則意味著由激活函數帶來的非線性變換的嵌套層數更多，就能構造更覆雜的映射關系。

## 3.3 超參數

### 3.3.1 什麽是超參數？

​	**超參數** : 在機器學習的上下文中，超參數是在開始學習過程之前設置值的參數，而不是通過訓練得到的參數數據。通常情況下，需要對超參數進行優化，給學習機選擇一組最優超參數，以提高學習的性能和效果。

​	超參數通常存在於：

    1.  定義關於模型的更高層次的概念，如覆雜性或學習能力。
    2.  不能直接從標準模型培訓過程中的數據中學習，需要預先定義。
    3.  可以通過設置不同的值，訓練不同的模型和選擇更好的測試值來決定

​	超參數具體來講比如算法中的學習率（learning rate）、梯度下降法叠代的數量（iterations）、隱藏層數目（hidden layers）、隱藏層單元數目、激活函數（ activation function）都需要根據實際情況來設置，這些數字實際上控制了最後的參數和的值，所以它們被稱作超參數。

### 3.3.2 如何尋找超參數的最優值？

​	在使用機器學習算法時，總有一些難調的超參數。例如權重衰減大小，高斯核寬度等等。這些參數需要人為設置，設置的值對結果產生較大影響。常見設置超參數的方法有：

1. 猜測和檢查：根據經驗或直覺，選擇參數，一直叠代。

2. 網格搜索：讓計算機嘗試在一定範圍內均勻分布的一組值。

3. 隨機搜索：讓計算機隨機挑選一組值。

4. 貝葉斯優化：使用貝葉斯優化超參數，會遇到貝葉斯優化算法本身就需要很多的參數的困難。

5. MITIE方法，好初始猜測的前提下進行局部優化。它使用BOBYQA算法，並有一個精心選擇的起始點。由於BOBYQA只尋找最近的局部最優解，所以這個方法是否成功很大程度上取決於是否有一個好的起點。在MITIE的情況下，我們知道一個好的起點，但這不是一個普遍的解決方案，因為通常你不會知道好的起點在哪里。從好的方面來說，這種方法非常適合尋找局部最優解。稍後我會再討論這一點。

6. 最新提出的LIPO的全局優化方法。這個方法沒有參數，而且經驗證比隨機搜索方法好。

### 3.3.3 超參數搜索一般過程？

超參數搜索一般過程：
1. 將數據集劃分成訓練集、驗證集及測試集。
2. 在訓練集上根據模型的性能指標對模型參數進行優化。
3. 在驗證集上根據模型的性能指標對模型的超參數進行搜索。
4. 步驟 2 和步驟 3 交替叠代，最終確定模型的參數和超參數，在測試集中驗證評價模型的優劣。

其中，搜索過程需要搜索算法，一般有：網格搜索、隨機搜過、啟发式智能搜索、貝葉斯搜索。

## 3.4 激活函數

### 3.4.1 為什麽需要非線性激活函數？

**為什麽需要激活函數？**

1. 激活函數對模型學習、理解非常覆雜和非線性的函數具有重要作用。
2. 激活函數可以引入非線性因素。如果不使用激活函數，則輸出信號僅是一個簡單的線性函數。線性函數一個一級多項式，線性方程的覆雜度有限，從數據中學習覆雜函數映射的能力很小。沒有激活函數，神經網絡將無法學習和模擬其他覆雜類型的數據，例如圖像、視頻、音頻、語音等。
3. 激活函數可以把當前特征空間通過一定的線性映射轉換到另一個空間，讓數據能夠更好的被分類。

**為什麽激活函數需要非線性函數？**

1. 假若網絡中全部是線性部件，那麽線性的組合還是線性，與單獨一個線性分類器無異。這樣就做不到用非線性來逼近任意函數。
2. 使用非線性激活函數 ，以便使網絡更加強大，增加它的能力，使它可以學習覆雜的事物，覆雜的表單數據，以及表示輸入輸出之間非線性的覆雜的任意函數映射。使用非線性激活函數，能夠從輸入輸出之間生成非線性映射。

### 3.4.2 常見的激活函數及圖像

1. sigmoid 激活函數

   函數的定義為：$ f(x) = \frac{1}{1 + e^{-x}} $，其值域為 $ (0,1) $。

   函數圖像如下：

![](/public/img/deep-learning-03/3-26.png)

2. tanh激活函數

   函數的定義為：$ f(x) = tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}} $，值域為 $ (-1,1) $。

   函數圖像如下：

![](/public/img/deep-learning-03/3-27.png)

3. Relu激活函數

   函數的定義為：$ f(x) = max(0, x) $  ，值域為 $ [0,+∞) $；

   函數圖像如下：

![](/public/img/deep-learning-03/3-28.png)

4. Leak Relu 激活函數 

   函數定義為： 
   $$ f(x) =  \left\{
   \begin{aligned}
   ax, \quad x<0 \\
   x, \quad x>0
   \end{aligned}
   \right. $$，值域為 $ (-∞,+∞) $。 

   圖像如下（$ a = 0.5 $）：

![](/public/img/deep-learning-03/3-29.png)

5. SoftPlus 激活函數

   函數的定義為：$ f(x) = ln( 1 + e^x) $，值域為 $ (0,+∞) $。

   函數圖像如下:

![](/public/img/deep-learning-03/3-30.png)

6. softmax 函數

   函數定義為： $$\sigma(z)_j = \frac{e^{z_j}}{\sum_{k=1}^K e^{z_k}} $$。

   Softmax 多用於多分類神經網絡輸出。

### 3.4.3 常見激活函數的導數計算？

對常見激活函數，導數計算如下：

| 原函數          | 函數表達式                                   | 導數                                                         | 備注                                                         |
| --------------- | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Sigmoid激活函數 | $f(x)=\frac{1}{1+e^{-x}}$                    | $f^{'}(x)=\frac{1}{1+e^{-x}}\left( 1- \frac{1}{1+e^{-x}} \right)=f(x)(1-f(x))$ | 當$x=10$,或$x=-10​$，$f^{'}(x) \approx0​$,當$x=0​$$f^{'}(x) =0.25​$ |
| Tanh激活函數    | $f(x)=tanh(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}$ | $f^{'}(x)=-(tanh(x))^2$                                      | 當$x=10$,或$x=-10$，$f^{'}(x) \approx0$,當$x=0$$f^{`}(x) =1$ |
| Relu激活函數    | $f(x)=max(0,x)$                              | $c(u)=\begin{cases} 0,x<0 \\ 1,x>0 \\ undefined,x=0\end{cases}$ | 通常$x=0$時，給定其導數為1和0                                |

### 3.4.4 激活函數有哪些性質？

1. 非線性： 當激活函數是非線性的，一個兩層的神經網絡就可以基本上逼近所有的函數。但如果激活函數是恒等激活函數的時候，即 $ f(x)=x $，就不滿足這個性質，而且如果 MLP 使用的是恒等激活函數，那麽其實整個網絡跟單層神經網絡是等價的；
2. 可微性： 當優化方法是基於梯度的時候，就體現了該性質；
3. 單調性： 當激活函數是單調的時候，單層網絡能夠保證是凸函數；
4. $ f(x)≈x $： 當激活函數滿足這個性質的時候，如果參數的初始化是隨機的較小值，那麽神經網絡的訓練將會很高效；如果不滿足這個性質，那麽就需要詳細地去設置初始值；
5. 輸出值的範圍： 當激活函數輸出值是有限的時候，基於梯度的優化方法會更加穩定，因為特征的表示受有限權值的影響更顯著；當激活函數的輸出是無限的時候，模型的訓練會更加高效，不過在這種情況小，一般需要更小的 Learning Rate。

### 3.4.5 如何選擇激活函數？

​	選擇一個適合的激活函數並不容易，需要考慮很多因素，通常的做法是，如果不確定哪一個激活函數效果更好，可以把它們都試試，然後在驗證集或者測試集上進行評價。然後看哪一種表現的更好，就去使用它。

以下是常見的選擇情況：

1. 如果輸出是 0、1 值（二分類問題），則輸出層選擇 sigmoid 函數，然後其它的所有單元都選擇 Relu 函數。
2. 如果在隱藏層上不確定使用哪個激活函數，那麽通常會使用 Relu 激活函數。有時，也會使用 tanh 激活函數，但 Relu 的一個優點是：當是負值的時候，導數等於 0。
3. sigmoid 激活函數：除了輸出層是一個二分類問題基本不會用它。
4. tanh 激活函數：tanh 是非常優秀的，幾乎適合所有場合。
5. ReLu 激活函數：最常用的默認函數，如果不確定用哪個激活函數，就使用 ReLu 或者 Leaky ReLu，再去嘗試其他的激活函數。
6. 如果遇到了一些死的神經元，我們可以使用 Leaky ReLU 函數。

### 3.4.6 使用 ReLu 激活函數的優點？

1. 在區間變動很大的情況下，ReLu 激活函數的導數或者激活函數的斜率都會遠大於 0，在程序實現就是一個 if-else 語句，而 sigmoid 函數需要進行浮點四則運算，在實踐中，使用 ReLu 激活函數神經網絡通常會比使用 sigmoid 或者 tanh 激活函數學習的更快。
2. sigmoid 和 tanh 函數的導數在正負飽和區的梯度都會接近於 0，這會造成梯度彌散，而 Relu 和Leaky ReLu 函數大於 0 部分都為常數，不會產生梯度彌散現象。
3. 需注意，Relu 進入負半區的時候，梯度為 0，神經元此時不會訓練，產生所謂的稀疏性，而 Leaky ReLu 不會產生這個問題。

### 3.4.7 什麽時候可以用線性激活函數？

1. 輸出層，大多使用線性激活函數。
2. 在隱含層可能會使用一些線性激活函數。
3. 一般用到的線性激活函數很少。

### 3.4.8 怎樣理解 Relu（< 0 時）是非線性激活函數？

Relu 激活函數圖像如下：

![](/public/img/deep-learning-03/3-32.png)

根據圖像可看出具有如下特點：

1. 單側抑制；

2. 相對寬闊的興奮邊界；

3. 稀疏激活性；

   ReLU 函數從圖像上看，是一個分段線性函數，把所有的負值都變為 0，而正值不變，這樣就成為單側抑制。

   因為有了這單側抑制，才使得神經網絡中的神經元也具有了稀疏激活性。

   **稀疏激活性**：從信號方面來看，即神經元同時只對輸入信號的少部分選擇性響應，大量信號被刻意的屏蔽了，這樣可以提高學習的精度，更好更快地提取稀疏特征。當 $ x<0 $ 時，ReLU 硬飽和，而當 $ x>0 $ 時，則不存在飽和問題。ReLU 能夠在 $ x>0 $ 時保持梯度不衰減，從而緩解梯度消失問題。

### 3.4.9 Softmax 定義及作用

Softmax 是一種形如下式的函數：
$$
P(i) = \frac{exp(\theta_i^T x)}{\sum_{k=1}^{K} exp(\theta_i^T x)}
$$
​	其中，$ \theta_i $ 和 $ x $ 是列向量，$ \theta_i^T x $ 可能被換成函數關於 $ x $ 的函數 $ f_i(x) $

​	通過 softmax 函數，可以使得 $ P(i) $ 的範圍在 $ [0,1] $ 之間。在回歸和分類問題中，通常 $ \theta $ 是待求參數，通過尋找使得 $ P(i) $ 最大的 $ \theta_i $ 作為最佳參數。

​	但是，使得範圍在 $ [0,1] $  之間的方法有很多，為啥要在前面加上以 $ e $ 的冪函數的形式呢？參考 logistic 函數：
$$
P(i) = \frac{1}{1+exp(-\theta_i^T x)}
$$
​	這個函數的作用就是使得 $ P(i) $ 在負無窮到 0 的區間趨向於 0， 在 0 到正無窮的區間趨向 1,。同樣 softmax 函數加入了 $ e $ 的冪函數正是為了兩極化：正樣本的結果將趨近於 1，而負樣本的結果趨近於 0。這樣為多類別提供了方便（可以把 $ P(i) $ 看做是樣本屬於類別的概率）。可以說，Softmax 函數是 logistic 函數的一種泛化。

​	softmax 函數可以把它的輸入，通常被稱為 logits 或者 logit scores，處理成 0 到 1 之間，並且能夠把輸出歸一化到和為 1。這意味著 softmax 函數與分類的概率分布等價。它是一個網絡預測多酚類問題的最佳輸出激活函數。

### 3.4.10 Softmax 函數如何應用於多分類？

​	softmax 用於多分類過程中，它將多個神經元的輸出，映射到 $ (0,1) $ 區間內，可以看成概率來理解，從而來進行多分類！

​	假設我們有一個數組，$ V_i $ 表示 $ V $  中的第 $ i $ 個元素，那麽這個元素的 softmax 值就是

$$
S_i = \frac{e^{V_i}}{\sum_j e^{V_j}}
$$

​	從下圖看，神經網絡中包含了輸入層，然後通過兩個特征層處理，最後通過 softmax 分析器就能得到不同條件下的概率，這里需要分成三個類別，最終會得到 $ y=0, y=1, y=2 $ 的概率值。

![](/public/img/deep-learning-03/3.4.9.1.png)

繼續看下面的圖，三個輸入通過 softmax 後得到一個數組 $ [0.05 , 0.10 , 0.85] $，這就是 soft 的功能。

![](/public/img/deep-learning-03/3.4.9.2.png)

更形象的映射過程如下圖所示：

![****](/public/img/deep-learning-03/3.4.9.3.png)

​	softmax 直白來說就是將原來輸出是 $ 3,1,-3 $ 通過 softmax 函數一作用，就映射成為 $ (0,1) $ 的值，而這些值的累和為 $ 1 $（滿足概率的性質），那麽我們就可以將它理解成概率，在最後選取輸出結點的時候，我們就可以選取概率最大（也就是值對應最大的）結點，作為我們的預測目標！

### 3.4.11 交叉熵代價函數定義及其求導推導

(**貢獻者：黃欽建－華南理工大學**)


​	神經元的輸出就是 a = σ(z)，其中$z=\sum w_{j}i_{j}+b$是輸⼊的帶權和。

$C=-\frac{1}{n}\sum[ylna+(1-y)ln(1-a)]$

​	其中 n 是訓練數據的總數，求和是在所有的訓練輸⼊ x 上進⾏的， y 是對應的⽬標輸出。

​	表達式是否解決學習緩慢的問題並不明顯。實際上，甚⾄將這個定義看做是代價函數也不是顯⽽易⻅的！在解決學習緩慢前，我們來看看交叉熵為何能夠解釋成⼀個代價函數。

​	將交叉熵看做是代價函數有兩點原因。

​	第⼀，它是⾮負的， C > 0。可以看出：式子中的求和中的所有獨⽴的項都是負數的，因為對數函數的定義域是 (0，1)，並且求和前⾯有⼀個負號，所以結果是非負。

​	第⼆，如果對於所有的訓練輸⼊ x，神經元實際的輸出接近⽬標值，那麽交叉熵將接近 0。

​	假設在這個例⼦中， y = 0 ⽽ a ≈ 0。這是我們想到得到的結果。我們看到公式中第⼀個項就消去了，因為 y = 0，⽽第⼆項實際上就是 − ln(1 − a) ≈ 0。反之， y = 1 ⽽ a ≈ 1。所以在實際輸出和⽬標輸出之間的差距越⼩，最終的交叉熵的值就越低了。（這里假設輸出結果不是0，就是1，實際分類也是這樣的）

​	綜上所述，交叉熵是⾮負的，在神經元達到很好的正確率的時候會接近 0。這些其實就是我們想要的代價函數的特性。其實這些特性也是⼆次代價函數具備的。所以，交叉熵就是很好的選擇了。但是交叉熵代價函數有⼀個⽐⼆次代價函數更好的特性就是它避免了學習速度下降的問題。為了弄清楚這個情況，我們來算算交叉熵函數關於權重的偏導數。我們將$a={\varsigma}(z)$代⼊到 公式中應⽤兩次鏈式法則，得到：

$$\begin{eqnarray}\frac{\partial C}{\partial w_{j}}&=&-\frac{1}{n}\sum \frac{\partial }{\partial w_{j}}[ylna+(1-y)ln(1-a)]\\&=&-\frac{1}{n}\sum \frac{\partial }{\partial a}[ylna+(1-y)ln(1-a)]*\frac{\partial a}{\partial w_{j}}\\&=&-\frac{1}{n}\sum (\frac{y}{a}-\frac{1-y}{1-a})*\frac{\partial a}{\partial w_{j}}\\&=&-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)})\frac{\partial \varsigma(z)}{\partial w_{j}}\\&=&-\frac{1}{n}\sum (\frac{y}{\varsigma(z)}-\frac{1-y}{1-\varsigma(z)}){\varsigma}'(z)x_{j}\end{eqnarray}$$

​	根據$\varsigma(z)=\frac{1}{1+e^{-z}}$ 的定義，和⼀些運算，我們可以得到 ${\varsigma}'(z)=\varsigma(z)(1-\varsigma(z))$。化簡後可得：

$\frac{\partial C}{\partial w_{j}}=\frac{1}{n}\sum x_{j}({\varsigma}(z)-y)$

​	這是⼀個優美的公式。它告訴我們權重學習的速度受到$\varsigma(z)-y$，也就是輸出中的誤差的控制。更⼤的誤差，更快的學習速度。這是我們直覺上期待的結果。特別地，這個代價函數還避免了像在⼆次代價函數中類似⽅程中${\varsigma}'(z)$導致的學習緩慢。當我們使⽤交叉熵的時候，${\varsigma}'(z)$被約掉了，所以我們不再需要關⼼它是不是變得很⼩。這種約除就是交叉熵帶來的特效。實際上，這也並不是⾮常奇跡的事情。我們在後⾯可以看到，交叉熵其實只是滿⾜這種特性的⼀種選擇罷了。

​	根據類似的⽅法，我們可以計算出關於偏置的偏導數。我這⾥不再給出詳細的過程，你可以輕易驗證得到：

$\frac{\partial C}{\partial b}=\frac{1}{n}\sum ({\varsigma}(z)-y)$


​	再⼀次, 這避免了⼆次代價函數中類似${\varsigma}'(z)$項導致的學習緩慢。

### 3.4.12 為什麽Tanh收斂速度比Sigmoid快？

**（貢獻者：黃欽建－華南理工大學）**

首先看如下兩個函數的求導：

$tanh^{,}(x)=1-tanh(x)^{2}\in (0,1)$

$s^{,}(x)=s(x)*(1-s(x))\in (0,\frac{1}{4}]$

由上面兩個公式可知tanh(x)梯度消失的問題比sigmoid輕，所以Tanh收斂速度比Sigmoid快。

3.4.13

### 3.4.12 內聚外斥 - Center Loss

**（貢獻者：李世軒－加州大學伯克利分校）**

在計算機視覺任務中, 由於其簡易性, 良好的表現, 與對分類任務的概率性理解, Cross Entropy Loss (交叉熵代價) + Softmax 組合被廣泛應用於以分類任務為代表的任務中. 在此應用下, 我們可將其學習過程進一步理解為: 更相似(同類/同物體)的圖像在特征域中擁有“更近的距離”, 相反則”距離更遠“. 換而言之, 我們可以進一步理解為其學習了一種低類內距離(Intra-class Distance)與高類間距離(Inter-class Distance)的特征判別模型. 在此Center Loss則可以高效的計算出這種具判別性的特征. 不同於傳統的Softmax Loss, Center Loss通過學習“特征中心”從而最小化其類內距離. 其表達形式如下:

$$L_{C} = \frac{1}{2}\sum^{m}_{i=1}||x_{i}-c_{y_{i}}||^{2}_{2}$$

其中$x_{i}$表示FCN(全連接層)之前的特征, $c_{y_{i}}$表示第$y_{i} $個類別的特征中心, $m$表示mini-batch的大小. 我們很清楚的看到$L_{C}$的終極目標為最小化每個特征與其特征中心的方差, 即最小化類內距離. 其叠代公式為:

$\frac{\partial L_{C}}{\partial x_{i}}=x_{i}-c_{y_{i}}$

$$\Delta{c_{j}} = \frac{\sum^{m}_{i=1}\delta(y_{i}=j)\cdot(c_{j}-x_{i})}{1+\sum^{m}_{i=1}\delta(y_{i}=j)}$$

其中$$\delta(condition)=\left\{
\begin{array}{rcl}
1       &      & {condition\ is\ True}\\
0     &      & {otherwise}\\ \end{array} \right.$$

結合Softmax, 我們可以搭配二者使用, 適當平衡這兩種監督信號. 在Softmax拉開類間距離的同時, 利用Center Loss最小化類內距離. 例如:

$$\begin{eqnarray}L & = & L_{S} + \lambda L_{C} \\ &=& -\sum^{m}_{i=1}log\frac{e^{W_{y}^{T}x_{i}+b_{y_{i}}}}{\sum^{m}_{i=1}e^{W^{T}_{j}x_{i}+b_{j}}} + \frac{\lambda}{2}\sum^{m}_{i=1}||x_{i}-c_{y_{i}}||^{2}_{2}\\ \end{eqnarray}$$

即便如此, Center Loss仍有它的不足之處: 其特征中心為存儲在網絡模型之外的額外參數, 不能與模型參數一同優化. 這些額外參數將與記錄每一步特征變化的自動回歸均值估計(autoregressive mean estimator)進行更叠. 當需要學習的類別數量較大時, mini-batch可能無力提供足夠的樣本進行均值估計. 若此Center Loss將需要平衡兩種監督損失來以確定更叠, 其過程需要一個對平衡超參數的搜索過程, 使得其擇值消耗昂貴.

## 3.5 Batch_Size

### 3.5.1 為什麽需要 Batch_Size？

Batch的選擇，首先決定的是下降的方向。

如果數據集比較小，可采用全數據集的形式，好處是：

1. 由全數據集確定的方向能夠更好地代表樣本總體，從而更準確地朝向極值所在的方向。
2. 由於不同權重的梯度值差別巨大，因此選取一個全局的學習率很困難。 Full Batch Learning 可以使用 Rprop 只基於梯度符號並且針對性單獨更新各權值。

對於更大的數據集，假如采用全數據集的形式，壞處是：
1. 隨著數據集的海量增長和內存限制，一次性載入所有的數據進來變得越來越不可行。
2. 以 Rprop 的方式叠代，會由於各個 Batch 之間的采樣差異性，各次梯度修正值相互抵消，無法修正。這才有了後來 RMSProp 的妥協方案。 

### 3.5.2 Batch_Size 值的選擇

​	假如每次只訓練一個樣本，即 Batch_Size = 1。線性神經元在均方誤差代價函數的錯誤面是一個拋物面，橫截面是橢圓。對於多層神經元、非線性網絡，在局部依然近似是拋物面。此時，每次修正方向以各自樣本的梯度方向修正，橫沖直撞各自為政，難以達到收斂。

​	既然 Batch_Size 為全數據集或者Batch_Size = 1都有各自缺點，可不可以選擇一個適中的Batch_Size值呢？

​	此時，可采用批梯度下降法（Mini-batches Learning）。因為如果數據集足夠充分，那麽用一半（甚至少得多）的數據訓練算出來的梯度與用全部數據訓練出來的梯度是幾乎一樣的。

### 3.5.3 在合理範圍內，增大Batch_Size有何好處？

1. 內存利用率提高了，大矩陣乘法的並行化效率提高。
2. 跑完一次 epoch（全數據集）所需的叠代次數減少，對於相同數據量的處理速度進一步加快。
3. 在一定範圍內，一般來說 Batch_Size 越大，其確定的下降方向越準，引起訓練震蕩越小。

### 3.5.4 盲目增大 Batch_Size 有何壞處？

1. 內存利用率提高了，但是內存容量可能撐不住了。
2. 跑完一次 epoch（全數據集）所需的叠代次數減少，要想達到相同的精度，其所花費的時間大大增加了，從而對參數的修正也就顯得更加緩慢。
3. Batch_Size 增大到一定程度，其確定的下降方向已經基本不再變化。

### 3.5.5 調節 Batch_Size 對訓練效果影響到底如何？

1. Batch_Size 太小，模型表現效果極其糟糕(error飆升)。
2. 隨著 Batch_Size 增大，處理相同數據量的速度越快。
3. 隨著 Batch_Size 增大，達到相同精度所需要的 epoch 數量越來越多。
4. 由於上述兩種因素的矛盾， Batch_Size 增大到某個時候，達到時間上的最優。
5. 由於最終收斂精度會陷入不同的局部極值，因此 Batch_Size 增大到某些時候，達到最終收斂精度上的最優。 

## 3.6 歸一化

### 3.6.1 歸一化含義？

1. 歸納統一樣本的統計分布性。歸一化在 $ 0-1$ 之間是統計的概率分布，歸一化在$ -1--+1$ 之間是統計的坐標分布。

2. 無論是為了建模還是為了計算，首先基本度量單位要同一，神經網絡是以樣本在事件中的統計分別幾率來進行訓練（概率計算）和預測，且 sigmoid 函數的取值是 0 到 1 之間的，網絡最後一個節點的輸出也是如此，所以經常要對樣本的輸出歸一化處理。

3. 歸一化是統一在 $ 0-1 $ 之間的統計概率分布，當所有樣本的輸入信號都為正值時，與第一隱含層神經元相連的權值只能同時增加或減小，從而導致學習速度很慢。

4. 另外在數據中常存在奇異樣本數據，奇異樣本數據存在所引起的網絡訓練時間增加，並可能引起網絡無法收斂。為了避免出現這種情況及後面數據處理的方便，加快網絡學習速度，可以對輸入信號進行歸一化，使得所有樣本的輸入信號其均值接近於 0 或與其均方差相比很小。

### 3.6.2 為什麽要歸一化？

1. 為了後面數據處理的方便，歸一化的確可以避免一些不必要的數值問題。
2. 為了程序運行時收斂加快。 
3. 同一量綱。樣本數據的評價標準不一樣，需要對其量綱化，統一評價標準。這算是應用層面的需求。
4. 避免神經元飽和。啥意思？就是當神經元的激活在接近 0 或者 1 時會飽和，在這些區域，梯度幾乎為 0，這樣，在反向傳播過程中，局部梯度就會接近 0，這會有效地“殺死”梯度。
5. 保證輸出數據中數值小的不被吞食。 

### 3.6.3 為什麽歸一化能提高求解最優解速度？

![](/public/img/deep-learning-03/3.6.3.1.png)

​	上圖是代表數據是否均一化的最優解尋解過程（圓圈可以理解為等高線）。左圖表示未經歸一化操作的尋解過程，右圖表示經過歸一化後的尋解過程。

​	當使用梯度下降法尋求最優解時，很有可能走“之字型”路線（垂直等高線走），從而導致需要叠代很多次才能收斂；而右圖對兩個原始特征進行了歸一化，其對應的等高線顯得很圓，在梯度下降進行求解時能較快的收斂。

​	因此如果機器學習模型使用梯度下降法求最優解時，歸一化往往非常有必要，否則很難收斂甚至不能收斂。

### 3.6.4 3D 圖解未歸一化

例子：

​	假設 $ w1 $ 的範圍在 $ [-10, 10] $，而 $ w2 $ 的範圍在 $ [-100, 100] $，梯度每次都前進 1 單位，那麽在 $ w1 $ 方向上每次相當於前進了 $ 1/20 $，而在 $ w2 $ 上只相當於 $ 1/200 $！某種意義上來說，在 $ w2 $ 上前進的步長更小一些,而 $ w1 $ 在搜索過程中會比 $ w2 $ “走”得更快。

​	這樣會導致，在搜索過程中更偏向於 $ w1 $ 的方向。走出了“L”形狀，或者成為“之”字形。

![](/public/img/deep-learning-03/3-37.png)

### 3.6.5 歸一化有哪些類型？

1. 線性歸一化

$$
x^{\prime} = \frac{x-min(x)}{max(x) - min(x)}
$$

​	適用範圍：比較適用在數值比較集中的情況。

​	缺點：如果 max 和 min 不穩定，很容易使得歸一化結果不穩定，使得後續使用效果也不穩定。

2. 標準差標準化

$$
x^{\prime} = \frac{x-\mu}{\sigma}
$$

​	含義：經過處理的數據符合標準正態分布，即均值為 0，標準差為 1 其中 $ \mu $ 為所有樣本數據的均值，$ \sigma $ 為所有樣本數據的標準差。

3. 非線性歸一化

   適用範圍：經常用在數據分化比較大的場景，有些數值很大，有些很小。通過一些數學函數，將原始值進行映射。該方法包括 $ log $、指數，正切等。

### 3.6.6 局部響應歸一化作用

​	LRN 是一種提高深度學習準確度的技術方法。LRN 一般是在激活、池化函數後的一種方法。

​	在 ALexNet 中，提出了 LRN 層，對局部神經元的活動創建競爭機制，使其中響應比較大對值變得相對更大，並抑制其他反饋較小的神經元，增強了模型的泛化能力。

### 3.6.7 理解局部響應歸一化

​	局部響應歸一化原理是仿造生物學上活躍的神經元對相鄰神經元的抑制現象（側抑制），其公式如下：

$$
b_{x,y}^i = a_{x,y}^i / (k + \alpha \sum_{j=max(0, i-n/2)}^{min(N-1, i+n/2)}(a_{x,y}^j)^2 )^\beta
$$

其中，
1) $ a $：表示卷積層（包括卷積操作和池化操作）後的輸出結果，是一個四維數組[batch,height,width,channel]。

- batch：批次數(每一批為一張圖片)。
- height：圖片高度。
- width：圖片寬度。
- channel：通道數。可以理解成一批圖片中的某一個圖片經過卷積操作後輸出的神經元個數，或理解為處理後的圖片深度。

2) $ a_{x,y}^i $ 表示在這個輸出結構中的一個位置 $ [a,b,c,d] $，可以理解成在某一張圖中的某一個通道下的某個高度和某個寬度位置的點，即第 $ a $ 張圖的第 $ d $ 個通道下的高度為b寬度為c的點。

3) $ N $：論文公式中的 $ N $ 表示通道數 (channel)。

4) $ a $，$ n/2 $， $ k $ 分別表示函數中的 input,depth_radius,bias。參數 $ k, n, \alpha, \beta $ 都是超參數，一般設置 $ k=2, n=5, \alpha=1*e-4, \beta=0.75 $

5) $ \sum $：$ \sum $ 疊加的方向是沿著通道方向的，即每個點值的平方和是沿著 $ a $ 中的第 3 維 channel 方向的，也就是一個點同方向的前面 $ n/2 $ 個通道（最小為第 $ 0 $ 個通道）和後 $ n/2 $ 個通道（最大為第 $ d-1 $ 個通道）的點的平方和(共 $ n+1 $ 個點)。而函數的英文注解中也說明了把 input 當成是 $ d $ 個 3 維的矩陣，說白了就是把 input 的通道數當作 3 維矩陣的個數，疊加的方向也是在通道方向。 

簡單的示意圖如下：

![](/public/img/deep-learning-03/3.6.7.1.png)

### 3.6.8 什麽是批歸一化（Batch Normalization）

​	以前在神經網絡訓練中，只是對輸入層數據進行歸一化處理，卻沒有在中間層進行歸一化處理。要知道，雖然我們對輸入數據進行了歸一化處理，但是輸入數據經過 $ \sigma(WX+b) $ 這樣的矩陣乘法以及非線性運算之後，其數據分布很可能被改變，而隨著深度網絡的多層運算之後，數據分布的變化將越來越大。如果我們能在網絡的中間也進行歸一化處理，是否對網絡的訓練起到改進作用呢？答案是肯定的。 

​	這種在神經網絡中間層也進行歸一化處理，使訓練效果更好的方法，就是批歸一化Batch Normalization（BN）。

### 3.6.9 批歸一化（BN）算法的優點

下面我們來說一下BN算法的優點： 
1. 減少了人為選擇參數。在某些情況下可以取消 dropout 和 L2 正則項參數,或者采取更小的 L2 正則項約束參數； 
2. 減少了對學習率的要求。現在我們可以使用初始很大的學習率或者選擇了較小的學習率，算法也能夠快速訓練收斂； 
3. 可以不再使用局部響應歸一化。BN 本身就是歸一化網絡(局部響應歸一化在 AlexNet 網絡中存在) 
4. 破壞原來的數據分布，一定程度上緩解過擬合（防止每批訓練中某一個樣本經常被挑選到，文獻說這個可以提高 1% 的精度）。 
5. 減少梯度消失，加快收斂速度，提高訓練精度。

### 3.6.10 批歸一化（BN）算法流程

下面給出 BN 算法在訓練時的過程

輸入：上一層輸出結果 $ X = {x_1, x_2, ..., x_m} $，學習參數 $ \gamma, \beta $

算法流程：

1. 計算上一層輸出數據的均值

$$
\mu_{\beta} = \frac{1}{m} \sum_{i=1}^m(x_i)
$$

其中，$ m $ 是此次訓練樣本 batch 的大小。

2. 計算上一層輸出數據的標準差

$$
\sigma_{\beta}^2 = \frac{1}{m} \sum_{i=1}^m (x_i - \mu_{\beta})^2
$$

3. 歸一化處理，得到

$$
\hat x_i = \frac{x_i + \mu_{\beta}}{\sqrt{\sigma_{\beta}^2} + \epsilon}
$$

其中 $ \epsilon $ 是為了避免分母為 0 而加進去的接近於 0 的很小值

4. 重構，對經過上面歸一化處理得到的數據進行重構，得到

$$
y_i = \gamma \hat x_i + \beta
$$

其中，$ \gamma, \beta $ 為可學習參數。

注：上述是 BN 訓練時的過程，但是當在投入使用時，往往只是輸入一個樣本，沒有所謂的均值 $ \mu_{\beta} $ 和標準差 $ \sigma_{\beta}^2 $。此時，均值 $ \mu_{\beta} $ 是計算所有 batch $ \mu_{\beta} $ 值的平均值得到，標準差 $ \sigma_{\beta}^2 $ 采用每個batch $ \sigma_{\beta}^2 $  的無偏估計得到。

### 3.6.11 批歸一化和群組歸一化比較

| 名稱                                           | 特點                                                         |
| ---------------------------------------------- | :----------------------------------------------------------- |
| 批量歸一化（Batch Normalization，以下簡稱 BN） | 可讓各種網絡並行訓練。但是，批量維度進行歸一化會帶來一些問題——批量統計估算不準確導致批量變小時，BN 的誤差會迅速增加。在訓練大型網絡和將特征轉移到計算機視覺任務中（包括檢測、分割和視頻），內存消耗限制了只能使用小批量的 BN。 |
| 群組歸一化 Group Normalization (簡稱 GN)       | GN 將通道分成組，並在每組內計算歸一化的均值和方差。GN 的計算與批量大小無關，並且其準確度在各種批量大小下都很穩定。 |
| 比較                                           | 在 ImageNet 上訓練的 ResNet-50上，GN 使用批量大小為 2 時的錯誤率比 BN 的錯誤率低 10.6％ ;當使用典型的批量時，GN 與 BN 相當，並且優於其他標歸一化變體。而且，GN 可以自然地從預訓練遷移到微調。在進行 COCO 中的目標檢測和分割以及 Kinetics 中的視頻分類比賽中，GN 可以勝過其競爭對手，表明 GN 可以在各種任務中有效地取代強大的 BN。 |

### 3.6.12 Weight Normalization和Batch Normalization比較

​	Weight Normalization 和 Batch Normalization 都屬於參數重寫（Reparameterization）的方法，只是采用的方式不同。

​	Weight Normalization 是對網絡權值$  W $ 進行 normalization，因此也稱為 Weight Normalization；

​	Batch Normalization 是對網絡某一層輸入數據進行 normalization。

​	Weight Normalization相比Batch Normalization有以下三點優勢：

1. Weight Normalization 通過重寫深度學習網絡的權重W的方式來加速深度學習網絡參數收斂，沒有引入 minbatch 的依賴，適用於 RNN（LSTM）網絡（Batch Normalization 不能直接用於RNN，進行 normalization 操作，原因在於：1) RNN 處理的 Sequence 是變長的；2) RNN 是基於 time step 計算，如果直接使用 Batch Normalization 處理，需要保存每個 time step 下，mini btach 的均值和方差，效率低且占內存）。

2. Batch Normalization 基於一個 mini batch 的數據計算均值和方差，而不是基於整個 Training set 來做，相當於進行梯度計算式引入噪聲。因此，Batch Normalization 不適用於對噪聲敏感的強化學習、生成模型（Generative model：GAN，VAE）使用。相反，Weight Normalization 對通過標量 $ g $ 和向量 $ v $ 對權重 $ W $ 進行重寫，重寫向量 $ v $ 是固定的，因此，基於 Weight Normalization 的 Normalization 可以看做比 Batch Normalization 引入更少的噪聲。    

3. 不需要額外的存儲空間來保存 mini batch 的均值和方差，同時實現 Weight Normalization 時，對深度學習網絡進行正向信號傳播和反向梯度計算帶來的額外計算開銷也很小。因此，要比采用 Batch Normalization 進行 normalization 操作時，速度快。  但是 Weight Normalization 不具備 Batch Normalization 把網絡每一層的輸出 Y 固定在一個變化範圍的作用。因此，采用 Weight Normalization 進行 Normalization 時需要特別注意參數初始值的選擇。

### 3.6.13 Batch Normalization在什麽時候用比較合適？

**（貢獻者：黃欽建－華南理工大學）**

​	在CNN中，BN應作用在非線性映射前。在神經網絡訓練時遇到收斂速度很慢，或梯度爆炸等無法訓練的狀況時可以嘗試BN來解決。另外，在一般使用情況下也可以加入BN來加快訓練速度，提高模型精度。

​	BN比較適用的場景是：每個mini-batch比較大，數據分布比較接近。在進行訓練之前，要做好充分的shuffle，否則效果會差很多。另外，由於BN需要在運行過程中統計每個mini-batch的一階統計量和二階統計量，因此不適用於動態的網絡結構和RNN網絡。


## 3.7 預訓練與微調(fine tuning)

### 3.7.1 為什麽無監督預訓練可以幫助深度學習？
深度網絡存在問題:

1. 網絡越深，需要的訓練樣本數越多。若用監督則需大量標注樣本，不然小規模樣本容易造成過擬合。深層網絡特征比較多，會出現的多特征問題主要有多樣本問題、規則化問題、特征選擇問題。

2. 多層神經網絡參數優化是個高階非凸優化問題，經常得到收斂較差的局部解；

3. 梯度擴散問題，BP算法計算出的梯度隨著深度向前而顯著下降，導致前面網絡參數貢獻很小，更新速度慢。

**解決方法：**

​	逐層貪婪訓練，無監督預訓練（unsupervised pre-training）即訓練網絡的第一個隱藏層，再訓練第二個…最後用這些訓練好的網絡參數值作為整體網絡參數的初始值。

經過預訓練最終能得到比較好的局部最優解。

### 3.7.2 什麽是模型微調fine tuning

​	用別人的參數、修改後的網絡和自己的數據進行訓練，使得參數適應自己的數據，這樣一個過程，通常稱之為微調（fine tuning). 

**模型的微調舉例說明：**

​	我們知道，CNN 在圖像識別這一領域取得了巨大的進步。如果想將 CNN 應用到我們自己的數據集上，這時通常就會面臨一個問題：通常我們的 dataset 都不會特別大，一般不會超過 1 萬張，甚至更少，每一類圖片只有幾十或者十幾張。這時候，直接應用這些數據訓練一個網絡的想法就不可行了，因為深度學習成功的一個關鍵性因素就是大量帶標簽數據組成的訓練集。如果只利用手頭上這點數據，即使我們利用非常好的網絡結構，也達不到很高的 performance。這時候，fine-tuning 的思想就可以很好解決我們的問題：我們通過對 ImageNet 上訓練出來的模型（如CaffeNet,VGGNet,ResNet) 進行微調，然後應用到我們自己的數據集上。

### 3.7.3 微調時候網絡參數是否更新？

答案：會更新。

1. finetune 的過程相當於繼續訓練，跟直接訓練的區別是初始化的時候。 
2. 直接訓練是按照網絡定義指定的方式初始化。
3. finetune是用你已經有的參數文件來初始化。

### 3.7.4 fine-tuning 模型的三種狀態

1. 狀態一：只預測，不訓練。
特點：相對快、簡單，針對那些已經訓練好，現在要實際對未知數據進行標注的項目，非常高效；

2. 狀態二：訓練，但只訓練最後分類層。
特點：fine-tuning的模型最終的分類以及符合要求，現在只是在他們的基礎上進行類別降維。

3. 狀態三：完全訓練，分類層+之前卷積層都訓練
特點：跟狀態二的差異很小，當然狀態三比較耗時和需要訓練GPU資源，不過非常適合fine-tuning到自己想要的模型里面，預測精度相比狀態二也提高不少。

## 3.8 權重偏差初始化

### 3.8.1 全都初始化為 0

**偏差初始化陷阱**： 都初始化為 0。

**產生陷阱原因**：因為並不知道在訓練神經網絡中每一個權重最後的值，但是如果進行了恰當的數據歸一化後，我們可以有理由認為有一半的權重是正的，另一半是負的。令所有權重都初始化為 0，如果神經網絡計算出來的輸出值是一樣的，神經網絡在進行反向傳播算法計算出來的梯度值也一樣，並且參數更新值也一樣。更一般地說，如果權重初始化為同一個值，網絡就是對稱的。

**形象化理解**：在神經網絡中考慮梯度下降的時候，設想你在爬山，但身處直線形的山谷中，兩邊是對稱的山峰。由於對稱性，你所在之處的梯度只能沿著山谷的方向，不會指向山峰；你走了一步之後，情況依然不變。結果就是你只能收斂到山谷中的一個極大值，而走不到山峰上去。

### 3.8.2 全都初始化為同樣的值

​	偏差初始化陷阱： 都初始化為一樣的值。
​	以一個三層網絡為例：
首先看下結構

![](/public/img/deep-learning-03/3.8.2.1.png)

它的表達式為： 

$$
a_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)})
$$

$$
a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 + b_2^{(1)})
$$

$$
a_3^{(2)} = f(W_{31}^{(1)} x_1 + W_{32}^{(1)} x_2 + W_{33}^{(1)} x_3 + b_3^{(1)})
$$

$$
h_{W,b}(x) = a_1^{(3)} = f(W_{11}^{(2)} a_1^{(2)} + W_{12}^{(2)} a_2^{(2)} + W_{13}^{(2)} a_3^{(2)} + b_1^{(2)})
$$

$$
xa_1^{(2)} = f(W_{11}^{(1)} x_1 + W_{12}^{(1)} x_2 + W_{13}^{(1)} x_3 + b_1^{(1)})a_2^{(2)} = f(W_{21}^{(1)} x_1 + W_{22}^{(1)} x_2 + W_{23}^{(1)} x_3 + 
$$

如果每個權重都一樣，那麽在多層網絡中，從第二層開始，每一層的輸入值都是相同的了也就是$ a1=a2=a3=.... $，既然都一樣，就相當於一個輸入了，為啥呢？？

如果是反向傳遞算法（如果這里不明白請看上面的連接），其中的偏置項和權重項的叠代的偏導數計算公式如下

$$
\frac{\partial}{\partial W_{ij}^{(l)}} J(W,b;x,y) = a_j^{(l)} \delta_i^{(l+1)}

\frac{\partial}{\partial b_{i}^{(l)}} J(W,b;x,y) = \delta_i^{(l+1)}
$$

$ \delta $ 的計算公式

$$
\delta_i^{(l)} = (\sum_{j=1}^{s_{t+1}} W_{ji}^{(l)} \delta_j^{(l+1)} ) f^{\prime}(z_i^{(l)})
$$


如果用的是 sigmoid 函數

$$
f^{\prime}(z_i^{(l)}) = a_i^{(l)}(1-a_i^{(l)})
$$

把後兩個公式代入，可以看出所得到的梯度下降法的偏導相同，不停的叠代，不停的相同，不停的叠代，不停的相同......，最後就得到了相同的值（權重和截距）。

### 3.8.3 初始化為小的隨機數

​	將權重初始化為很小的數字是一個普遍的打破網絡對稱性的解決辦法。這個想法是，神經元在一開始都是隨機的、獨一無二的，所以它們會計算出不同的更新，並將自己整合到整個網絡的各個部分。一個權重矩陣的實現可能看起來像 $ W=0.01∗np.random.randn(D,H) $，其中 randn 是從均值為 0 的單位標準高斯分布進行取樣。通過這個公式(函數)，每個神經元的權重向量初始化為一個從多維高斯分布取樣的隨機向量，所以神經元在輸入空間中指向隨機的方向(so the neurons point in random direction in the input space). 應該是指輸入空間對於隨機方向有影響)。其實也可以從均勻分布中來隨機選取小數，但是在實際操作中看起來似乎對最後的表現並沒有太大的影響。

​	備注：並不是數字越小就會表現的越好。比如，如果一個神經網絡層的權重非常小，那麽在反向傳播算法就會計算出很小的梯度(因為梯度 gradient 是與權重成正比的)。在網絡不斷的反向傳播過程中將極大地減少“梯度信號”，並可能成為深層網絡的一個需要注意的問題。

### 3.8.4 用 $ 1/\sqrt n $ 校準方差

​	上述建議的一個問題是，隨機初始化神經元的輸出的分布有一個隨輸入量增加而變化的方差。結果證明，我們可以通過將其權重向量按其輸入的平方根(即輸入的數量)進行縮放，從而將每個神經元的輸出的方差標準化到 1。也就是說推薦的啟发式方法 (heuristic) 是將每個神經元的權重向量按下面的方法進行初始化: $ w=np.random.randn(n)/\sqrt n $，其中 n 表示輸入的數量。這保證了網絡中所有的神經元最初的輸出分布大致相同，並在經驗上提高了收斂速度。

### 3.8.5 稀疏初始化(Sparse Initialazation)

​	另一種解決未校準方差問題的方法是把所有的權重矩陣都設為零，但是為了打破對稱性，每個神經元都是隨機連接地(從如上面所介紹的一個小的高斯分布中抽取權重)到它下面的一個固定數量的神經元。一個典型的神經元連接的數目可能是小到 10 個。

### 3.8.6 初始化偏差

​	將偏差初始化為零是可能的，也是很常見的，因為非對稱性破壞是由權重的小隨機數導致的。因為 ReLU 具有非線性特點，所以有些人喜歡使用將所有的偏差設定為小的常數值如 0.01，因為這樣可以確保所有的 ReLU 單元在最開始就激活觸发(fire)並因此能夠獲得和傳播一些梯度值。然而，這是否能夠提供持續的改善還不太清楚(實際上一些結果表明這樣做反而使得性能更加糟糕)，所以更通常的做法是簡單地將偏差初始化為 0.

## 3.9 學習率

### 3.9.1 學習率的作用

​	在機器學習中，監督式學習通過定義一個模型，並根據訓練集上的數據估計最優參數。梯度下降法是一個廣泛被用來最小化模型誤差的參數優化算法。梯度下降法通過多次叠代，並在每一步中最小化成本函數（cost 來估計模型的參數。學習率 (learning rate)，在叠代過程中會控制模型的學習進度。

​	在梯度下降法中，都是給定的統一的學習率，整個優化過程中都以確定的步長進行更新， 在叠代優化的前期中，學習率較大，則前進的步長就會較長，這時便能以較快的速度進行梯度下降，而在叠代優化的後期，逐步減小學習率的值，減小步長，這樣將有助於算法的收斂，更容易接近最優解。故而如何對學習率的更新成為了研究者的關注點。
​	在模型優化中，常用到的幾種學習率衰減方法有：分段常數衰減、多項式衰減、指數衰減、自然指數衰減、余弦衰減、線性余弦衰減、噪聲線性余弦衰減

### 3.9.2 學習率衰減常用參數有哪些

| 參數名稱          | 參數說明                                           |
| ----------------- | -------------------------------------------------- |
| learning_rate     | 初始學習率                                         |
| global_step       | 用於衰減計算的全局步數，非負，用於逐步計算衰減指數 |
| decay_steps       | 衰減步數，必須是正值，決定衰減周期                 |
| decay_rate        | 衰減率                                             |
| end_learning_rate | 最低的最終學習率                                   |
| cycle             | 學習率下降後是否重新上升                           |
| alpha             | 最小學習率                                         |
| num_periods       | 衰減余弦部分的周期數                               |
| initial_variance  | 噪聲的初始方差                                     |
| variance_decay    | 衰減噪聲的方差                                     |

### 3.9.3 分段常數衰減

​	分段常數衰減需要事先定義好的訓練次數區間，在對應區間置不同的學習率的常數值，一般情況剛開始的學習率要大一些，之後要越來越小，要根據樣本量的大小設置區間的間隔大小，樣本量越大，區間間隔要小一點。下圖即為分段常數衰減的學習率變化圖，橫坐標代表訓練次數，縱坐標代表學習率。

![](/public/img/deep-learning-03/learnrate1.png)

### 3.9.4 指數衰減

​	以指數衰減方式進行學習率的更新，學習率的大小和訓練次數指數相關，其更新規則為：
$$
decayed{\_}learning{\_}rate =learning{\_}rate*decay{\_}rate^{\frac{global{\_step}}{decay{\_}steps}}
$$
​	這種衰減方式簡單直接，收斂速度快，是最常用的學習率衰減方式，如下圖所示，綠色的為學習率隨
訓練次數的指數衰減方式，紅色的即為分段常數衰減，它在一定的訓練區間內保持學習率不變。

![](/public/img/deep-learning-03/learnrate2.png)

### 3.9.5 自然指數衰減

​	它與指數衰減方式相似，不同的在於它的衰減底數是$e$，故而其收斂的速度更快，一般用於相對比較
容易訓練的網絡，便於較快的收斂，其更新規則如下
$$
decayed{\_}learning{\_}rate =learning{\_}rate*e^{\frac{-decay{\_rate}}{global{\_}step}}
$$
​	下圖為為分段常數衰減、指數衰減、自然指數衰減三種方式的對比圖，紅色的即為分段常數衰減圖，階梯型曲線。藍色線為指數衰減圖，綠色即為自然指數衰減圖，很明可以看到自然指數衰減方式下的學習率衰減程度要大於一般指數衰減方式，有助於更快的收斂。

![](/public/img/deep-learning-03/learnrate3.png)

### 3.9.6 多項式衰減

​	應用多項式衰減的方式進行更新學習率，這里會給定初始學習率和最低學習率取值，然後將會按照
給定的衰減方式將學習率從初始值衰減到最低值,其更新規則如下式所示。
$$
global{\_}step=min(global{\_}step,decay{\_}steps)
$$

$$
decayed{\_}learning{\_}rate =(learning{\_}rate-end{\_}learning{\_}rate)* \left( 1-\frac{global{\_step}}{decay{\_}steps}\right)^{power} \\
 +end{\_}learning{\_}rate
$$

​	需要注意的是，有兩個機制，降到最低學習率後，到訓練結束可以一直使用最低學習率進行更新，另一個是再次將學習率調高，使用 decay_steps 的倍數，取第一個大於 global_steps 的結果，如下式所示.它是用來防止神經網絡在訓練的後期由於學習率過小而導致的網絡一直在某個局部最小值附近震蕩，這樣可以通過在後期增大學習率跳出局部極小值。
$$
decay{\_}steps = decay{\_}steps*ceil \left( \frac{global{\_}step}{decay{\_}steps}\right)
$$
​	如下圖所示，紅色線代表學習率降低至最低後，一直保持學習率不變進行更新，綠色線代表學習率衰減到最低後，又會再次循環往覆的升高降低。

![](/public/img/deep-learning-03/learnrate4.png)

### 3.9.7 余弦衰減

​	余弦衰減就是采用余弦的相關方式進行學習率的衰減，衰減圖和余弦函數相似。其更新機制如下式所示：
$$
global{\_}step=min(global{\_}step,decay{\_}steps)
$$

$$
cosine{\_}decay=0.5*\left( 1+cos\left( \pi* \frac{global{\_}step}{decay{\_}steps}\right)\right)
$$

$$
decayed=(1-\alpha)*cosine{\_}decay+\alpha
$$

$$
decayed{\_}learning{\_}rate=learning{\_}rate*decayed
$$

​	如下圖所示，紅色即為標準的余弦衰減曲線，學習率從初始值下降到最低學習率後保持不變。藍色的線是線性余弦衰減方式曲線，它是學習率從初始學習率以線性的方式下降到最低學習率值。綠色噪聲線性余弦衰減方式。

![](/public/img/deep-learning-03/learnrate5.png)

## 3.12 Dropout 系列問題

### 3.12.1 為什麽要正則化？   
1. 深度學習可能存在過擬合問題——高方差，有兩個解決方法，一個是正則化，另一個是準備更多的數據，這是非常可靠的方法，但你可能無法時時刻刻準備足夠多的訓練數據或者獲取更多數據的成本很高，但正則化通常有助於避免過擬合或減少你的網絡誤差。  
2. 如果你懷疑神經網絡過度擬合了數據，即存在高方差問題，那麽最先想到的方法可能是正則化，另一個解決高方差的方法就是準備更多數據，這也是非常可靠的辦法，但你可能無法時時準備足夠多的訓練數據，或者，獲取更多數據的成本很高，但正則化有助於避免過度擬合，或者減少網絡誤差。

### 3.12.2 為什麽正則化有利於預防過擬合？ 

![](/public/img/deep-learning-03/3.12.2.1.png) 
![](/public/img/deep-learning-03/3.12.2.2.png) 

左圖是高偏差，右圖是高方差，中間是Just Right，這幾張圖我們在前面課程中看到過。  

### 3.12.3 理解dropout正則化  
​	Dropout可以隨機刪除網絡中的神經單元，它為什麽可以通過正則化发揮如此大的作用呢？  

​	直觀上理解：不要依賴於任何一個特征，因為該單元的輸入可能隨時被清除，因此該單元通過這種方式傳播下去，並為單元的四個輸入增加一點權重，通過傳播所有權重，dropout將產生收縮權重的平方範數的效果，和之前講的L2正則化類似；實施dropout的結果實它會壓縮權重，並完成一些預防過擬合的外層正則化；L2對不同權重的衰減是不同的，它取決於激活函數倍增的大小。  

### 3.12.4 dropout率的選擇

1. 經過交叉驗證，隱含節點 dropout 率等於 0.5 的時候效果最好，原因是 0.5 的時候 dropout 隨機生成的網絡結構最多。
2. dropout 也可以被用作一種添加噪聲的方法，直接對 input 進行操作。輸入層設為更接近 1 的數。使得輸入變化不會太大（0.8） 
3. 對參數 $ w $ 的訓練進行球形限制 (max-normalization)，對 dropout 的訓練非常有用。
4. 球形半徑 $ c $ 是一個需要調整的參數，可以使用驗證集進行參數調優。
5. dropout 自己雖然也很牛，但是 dropout、max-normalization、large decaying learning rates and high momentum 組合起來效果更好，比如 max-norm regularization 就可以防止大的learning rate 導致的參數 blow up。
6. 使用 pretraining 方法也可以幫助 dropout 訓練參數，在使用 dropout 時，要將所有參數都乘以 $ 1/p $。

### 3.12.5 dropout有什麽缺點？  

​	dropout一大缺點就是代價函數J不再被明確定義，每次叠代，都會隨機移除一些節點，如果再三檢查梯度下降的性能，實際上是很難進行覆查的。定義明確的代價函數J每次叠代後都會下降，因為我們所優化的代價函數J實際上並沒有明確定義，或者說在某種程度上很難計算，所以我們失去了調試工具來繪制這樣的圖片。我通常會關閉dropout函數，將keep-prob的值設為1，運行代碼，確保J函數單調遞減。然後打開dropout函數，希望在dropout過程中，代碼並未引入bug。我覺得你也可以嘗試其它方法，雖然我們並沒有關於這些方法性能的數據統計，但你可以把它們與dropout方法一起使用。  

## 3.13 深度學習中常用的數據增強方法？

**（貢獻者：黃欽建－華南理工大學）**

- Color Jittering：對顏色的數據增強：圖像亮度、飽和度、對比度變化（此處對色彩抖動的理解不知是否得當）；

- PCA  Jittering：首先按照RGB三個顏色通道計算均值和標準差，再在整個訓練集上計算協方差矩陣，進行特征分解，得到特征向量和特征值，用來做PCA Jittering；

- Random Scale：尺度變換；

- Random Crop：采用隨機圖像差值方式，對圖像進行裁剪、縮放；包括Scale Jittering方法（VGG及ResNet模型使用）或者尺度和長寬比增強變換；

- Horizontal/Vertical Flip：水平/垂直翻轉；

- Shift：平移變換；

- Rotation/Reflection：旋轉/仿射變換；

- Noise：高斯噪聲、模糊處理；

- Label Shuffle：類別不平衡數據的增廣；

## 3.14 如何理解 Internal Covariate Shift？

**（貢獻者：黃欽建－華南理工大學）**

​	深度神經網絡模型的訓練為什麽會很困難？其中一個重要的原因是，深度神經網絡涉及到很多層的疊加，而每一層的參數更新會導致上層的輸入數據分布发生變化，通過層層疊加，高層的輸入分布變化會非常劇烈，這就使得高層需要不斷去重新適應底層的參數更新。為了訓好模型，我們需要非常謹慎地去設定學習率、初始化權重、以及盡可能細致的參數更新策略。

​	Google 將這一現象總結為 Internal Covariate Shift，簡稱 ICS。 什麽是 ICS 呢？

​	大家都知道在統計機器學習中的一個經典假設是“源空間（source domain）和目標空間（target domain）的數據分布（distribution）是一致的”。如果不一致，那麽就出現了新的機器學習問題，如 transfer learning / domain adaptation 等。而 covariate shift 就是分布不一致假設之下的一個分支問題，它是指源空間和目標空間的條件概率是一致的，但是其邊緣概率不同。

​	大家細想便會发現，的確，對於神經網絡的各層輸出，由於它們經過了層內操作作用，其分布顯然與各層對應的輸入信號分布不同，而且差異會隨著網絡深度增大而增大，可是它們所能“指示”的樣本標記（label）仍然是不變的，這便符合了covariate shift的定義。由於是對層間信號的分析，也即是“internal”的來由。

**那麽ICS會導致什麽問題？**

簡而言之，每個神經元的輸入數據不再是“獨立同分布”。

其一，上層參數需要不斷適應新的輸入數據分布，降低學習速度。

其二，下層輸入的變化可能趨向於變大或者變小，導致上層落入飽和區，使得學習過早停止。

其三，每層的更新都會影響到其它層，因此每層的參數更新策略需要盡可能的謹慎。





## 參考文獻

[1] Rosenblatt, F. The perceptron: A probabilistic model for information storage and organization in the brain.[J]. Psychological Review, 1958, 65(6):386-408.

[2] Duvenaud D , Rippel O , Adams R P , et al. Avoiding pathologies in very deep networks[J]. Eprint Arxiv, 2014:202-210.

[3] Rumelhart D E, Hinton G E, Williams R J. Learning representations by back-propagating errors[J]. Cognitive modeling, 1988, 5(3): 1.

[4] Hecht-Nielsen R. Theory of the backpropagation neural network[M]//Neural networks for perception. Academic Press, 1992: 65-93.

[5] Felice M. Which deep learning network is best for you?\| CIO[J]. 2017.

[6] Conneau A, Schwenk H, Barrault L, et al. Very deep convolutional networks for natural language processing[J]. arXiv preprint arXiv:1606.01781, 2016, 2.

[7] Ba J, Caruana R. Do deep nets really need to be deep?[C]//Advances in neural information processing systems. 2014: 2654-2662.

[8] Nielsen M A. Neural networks and deep learning[M]. USA: Determination press, 2015.

[9] Goodfellow I, Bengio Y, Courville A. Deep learning[M]. MIT press, 2016.

[10] 周志華. 機器學習[M].清華大學出版社, 2016.

[11] Kim J, Kwon Lee J, Mu Lee K. Accurate image super-resolution using very deep convolutional networks[C]//Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 1646-1654.

[12] Chen Y, Lin Z, Zhao X, et al. Deep learning-based classification of hyperspectral data[J]. IEEE Journal of Selected topics in applied earth observations and remote sensing, 2014, 7(6): 2094-2107.

[13] Domhan T, Springenberg J T, Hutter F. Speeding up automatic hyperparameter optimization of deep neural networks by extrapolation of learning curves[C]//Twenty-Fourth International Joint Conference on Artificial Intelligence. 2015.

[14] Maclaurin D, Duvenaud D, Adams R. Gradient-based hyperparameter optimization through reversible learning[C]//International Conference on Machine Learning. 2015: 2113-2122.

[15] Srivastava R K, Greff K, Schmidhuber J. Training very deep networks[C]//Advances in neural information processing systems. 2015: 2377-2385.

[16] Bergstra J, Bengio Y. Random search for hyper-parameter optimization[J]. Journal of Machine Learning Research, 2012, 13(Feb): 281-305.

[17] Ngiam J, Khosla A, Kim M, et al. Multimodal deep learning[C]//Proceedings of the 28th international conference on machine learning (ICML-11). 2011: 689-696.

[18] Deng L, Yu D. Deep learning: methods and applications[J]. Foundations and Trends® in Signal Processing, 2014, 7(3–4): 197-387.

[19] Erhan D, Bengio Y, Courville A, et al. Why does unsupervised pre-training help deep learning?[J]. Journal of Machine Learning Research, 2010, 11(Feb): 625-660.

[20] Dong C, Loy C C, He K, et al. Learning a deep convolutional network for image super resolution[C]//European conference on computer vision. Springer, Cham, 2014: 184-199.

[21] 鄭澤宇，梁博文，顧思宇.TensorFlow：實戰Google深度學習框架（第2版）[M].電子工業出版社,2018.

[22] 焦李成. 深度學習優化與識別[M].清華大學出版社,2017.

[23] 吳岸城. 神經網絡與深度學習[M].電子工業出版社,2016.

[24] Wei, W.G.H., Liu, T., Song, A., et al. (2018) An Adaptive Natural Gradient Method with Adaptive Step Size in Multilayer Perceptrons. Chinese Automation Congress, 1593-1597.

[25] Y Feng, Y Li.An Overview of Deep Learning Optimization Methods and Learning Rate Attenuation Methods[J].Hans Journal of Data Mining,2018,8(4),186-200.
