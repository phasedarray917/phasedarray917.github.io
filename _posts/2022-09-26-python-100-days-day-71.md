---
layout: post
title: Python 100 Days Day71 Introduction to Pandas-2
categories: Dev
tags: [beginner, python]
---

author: [jackfrued](https://github.com/jackfrued/Python-100-Days)

## Pandas的應用-2

### DataFrame的應用

#### 創建DataFrame對象

<!-- more -->

##### 通過二維數組創建`DataFrame`對象

代碼：

```python
scores = np.random.randint(60, 101, (5, 3))
courses = ['語文', '數學', '英語']
ids = [1001, 1002, 1003, 1004, 1005]
df1 = pd.DataFrame(data=scores, columns=courses, index=ids)
df1
```

輸出：

```
		語文	數學	英語
1001    69    80	79
1002    71	  60	100
1003    94    81	93
1004    88	  88	67
1005    82	  66    60
```

##### 通過字典創建`DataFrame`對象

代碼：

```python
scores = {
    '語文': [62, 72, 93, 88, 93],
    '數學': [95, 65, 86, 66, 87],
    '英語': [66, 75, 82, 69, 82],
}
ids = [1001, 1002, 1003, 1004, 1005]
df2 = pd.DataFrame(data=scores, index=ids)
df2
```

輸出：

```
		語文	數學	英語
1001    69    80	79
1002    71	  60	100
1003    94    81	93
1004    88	  88	67
1005    82	  66    60
```

##### 讀取 CSV 文件創建`DataFrame`對象

可以通過`pandas` 模塊的`read_csv`函數來讀取 CSV 文件，`read_csv`函數的參數非常多，下面接受幾個比較重要的參數。

- `sep` / `delimiter`：分隔符，默認是`,`。
- `header`：表頭（列索引）的位置，默認值是`infer`，用第一行的內容作為表頭（列索引）。
- `index_col`：用作行索引（標簽）的列。
- `usecols`：需要加載的列，可以使用序號或者列名。
- `true_values` / `false_values`：哪些值被視為布爾值`True` / `False`。
- `skiprows`：通過行號、索引或函數指定需要跳過的行。
- `skipfooter`：要跳過的末尾行數。
- `nrows`：需要讀取的行數。
- `na_values`：哪些值被視為空值。

代碼：

```python
df3 = pd.read_csv('2018年北京積分落戶數據.csv', index_col='id')
df3
```

輸出：

```
     name   birthday    company       score
id				
1    楊x    1972-12    北京利德xxxx	  122.59
2    紀x    1974-12    北京航天xxxx	  121.25
3    王x    1974-05	  品牌聯盟xxxx    118.96
4    楊x    1975-07	  中科專利xxxx    118.21
5    張x    1974-11	  北京阿里xxxx    117.79
...  ...    ...        ...            ...
6015 孫x    1978-08	  華為海洋xxxx	  90.75
6016 劉x    1976-11	  福斯流體xxxx    90.75
6017 周x    1977-10	  贏創德固xxxx    90.75
6018 趙x	   1979-07	  澳科利耳xxxx    90.75
6019 賀x	   1981-06	  北京寶潔xxxx    90.75
6019 rows × 4 columns
```

> **說明**：如果需要上面例子中的 CSV 文件，可以通過下面的百度雲盤地址進行獲取，數據在《從零開始學數據分析》目錄中。鏈接：https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g，提取碼：e7b4。

##### 讀取Excel文件創建`DataFrame`對象

可以通過`pandas` 模塊的`read_excel`函數來讀取 Exce l文件，該函數與上面的`read_csv`非常相近，多了一個`sheet_name`參數來指定數據表的名稱，但是不同於 CSV 文件，沒有`sep`或`delimiter`這樣的參數。下面的代碼中，`read_excel`函數的`skiprows`參數是一個 Lambda 函數，通過該 Lambda 函數指定只讀取 Excel 文件的表頭和其中10%的數據，跳過其他的數據。

代碼：

```python
import random

df4 = pd.read_excel(
    io='小寶劍大藥房2018年銷售數據.xlsx',
    usecols=['購藥時間', '社保卡號', '商品名稱', '銷售數量', '應收金額', '實收金額'],
    skiprows=lambda x: x > 0 and random.random() > 0.1
)
df4
```

> **說明**：如果需要上面例子中的 Excel 文件，可以通過下面的百度雲盤地址進行獲取，數據在《從零開始學數據分析》目錄中。鏈接：https://pan.baidu.com/s/1rQujl5RQn9R7PadB2Z5g_g，提取碼：e7b4。

輸出：

```
    購藥時間			社保卡號	    商品名稱    銷售數量	應收金額	實收金額
0	2018-03-23 星期三	10012157328		強力xx片	 1			13.8		13.80
1	2018-07-12 星期二	108207828	    強力xx片	 1	        13.8		13.80
2	2018-01-17 星期日	13358228	    清熱xx液	 1		    28.0		28.00
3	2018-07-11 星期一	10031402228		三九xx靈	 5			149.0		130.00
4	2018-01-20 星期三	10013340328		三九xx靈	 3			84.0		73.92
...	...					...				...		...			...			...
618	2018-03-05 星期六	10066059228		開博xx通	 2			56.0		49.28
619	2018-03-22 星期二	10035514928		開博xx通	 1			28.0		25.00
620	2018-04-15 星期五	1006668328	    開博xx通	 2			56.0		50.00
621	2018-04-24 星期日	10073294128		高特xx靈	 1			5.6			5.60
622	2018-04-24 星期日	10073294128		高特xx靈	 10			56.0		56.0
623 rows × 6 columns
```

##### 通過SQL從數據庫讀取數據創建`DataFrame`對象

`pandas`模塊的`read_sql`函數可以通過 SQL 語句從數據庫中讀取數據創建`DataFrame`對象，該函數的第二個參數代表了需要連接的數據庫。對於 MySQL 數據庫，我們可以通過`pymysql`或`mysqlclient`來創建數據庫連接，得到一個`Connection` 對象，而這個對象就是`read_sql`函數需要的第二個參數，代碼如下所示。

代碼：

```python
import pymysql

# 創建一個MySQL數據庫的連接對象
conn = pymysql.connect(
    host='47.104.31.138', port=3306,
    user='guest', password='Guest.618',
    database='hrs', charset='utf8mb4'
)
# 通過SQL從數據庫讀取數據創建DataFrame
df5 = pd.read_sql('select * from tb_emp', conn, index_col='eno')
df5
```

> **提示**：執行上面的代碼需要先安裝`pymysql`庫，如果尚未安裝，可以先在 Notebook 的單元格中先執行`!pip install pymysql`，然後再運行上面的代碼。上面的代碼連接的是我部署在阿里雲上的 MySQL 數據庫，公網 IP 地址：`47.104.31.138`，用戶名：`guest`，密碼：`Guest.618`，數據庫：`hrs`，表名：`tb_emp`，字符集：`utf8mb4`，大家可以使用這個數據庫，但是不要進行惡意的訪問。

輸出：

```
        ename    job     mgr      sal    comm    dno
eno						
1359	胡一刀   銷售員	3344.0   1800   200.0   30
2056	喬峰	   分析師	 7800.0   5000   1500.0	 20
3088	李莫愁	  設計師	2056.0   3500   800.0   20
3211	張無忌	  程序員	2056.0   3200   NaN     20
3233	丘處機	  程序員	2056.0   3400	NaN     20
3244	歐陽鋒	  程序員	3088.0   3200	NaN     20
3251	張翠山	  程序員	2056.0   4000	NaN     20
3344	黃蓉	   銷售主管	7800.0   3000	800.0   30
3577	楊過	   會計	  5566.0   2200   NaN	  10
3588	朱九真	  會計	 5566.0   2500   NaN	 10
4466	苗人鳳	  銷售員	3344.0   2500	NaN     30
5234	郭靖	   出納	  5566.0   2000   NaN	  10
5566	宋遠橋	  會計師	7800.0   4000   1000.0  10
7800	張三豐	  總裁	 NaN      9000   1200.0  20
```

#### 基本屬性和方法

在開始講解`DataFrame`的屬性和方法前，我們先從之前提到的`hrs`數據庫中讀取三張表的數據，創建出三個`DataFrame`對象，代碼如下所示。

```python
import pymysql

conn = pymysql.connect(
    host='47.104.31.138', port=3306, 
    user='guest', password='Guest.618', 
    database='hrs', charset='utf8mb4'
)
dept_df = pd.read_sql('select * from tb_dept', conn, index_col='dno')
emp_df = pd.read_sql('select * from tb_emp', conn, index_col='eno')
emp2_df = pd.read_sql('select * from tb_emp2', conn, index_col='eno')
```

得到的三個`DataFrame`對象如下所示。

部門表（`dept_df`），其中`dno`是部門的編號，`dname`和`dloc`分別是部門的名稱和所在地。

```
    dname  dloc
dno
10	會計部	北京
20	研發部	成都
30	銷售部	重慶
40	運維部	天津
```

員工表（`emp_df`），其中`eno`是員工編號，`ename`、`job`、`mgr`、`sal`、`comm`和`dno`分別代表員工的姓名、職位、主管編號、月薪、補貼和部門編號。

```
        ename    job        mgr      sal     comm    dno
eno
1359	胡一刀    銷售員	   3344.0	1800	200.0	30
2056	喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3088	李莫愁	   設計師	   2056.0	3500	800.0	20
3211	張無忌	   程序員	   2056.0	3200	NaN     20
3233	丘處機	   程序員	   2056.0	3400	NaN	    20
3244	歐陽鋒	   程序員	   3088.0	3200	NaN     20
3251	張翠山	   程序員	   2056.0	4000	NaN	    20
3344	黃蓉	    銷售主管   7800.0	3000	800.0	30
3577	楊過	    會計	     5566.0	  2200	  NaN	  10
3588	朱九真	   會計	    5566.0	 2500	 NaN	 10
4466	苗人鳳	   銷售員	   3344.0	2500	NaN	    30
5234	郭靖	    出納	     5566.0	  2000	  NaN	  10
5566	宋遠橋	   會計師	   7800.0	4000	1000.0	10
7800	張三豐	   總裁	    NaN      9000	 1200.0	 20
```

> **說明**：在數據庫中`mgr`和`comm`兩個列的數據類型是`int`，但是因為有缺失值（空值），讀取到`DataFrame`之後，列的數據類型變成了`float`，因為我們通常會用`float`類型的`NaN`來表示空值。

員工表（`emp2_df`），跟上面的員工表結構相同，但是保存了不同的員工數據。

```
        ename    job    mgr     sal      comm    dno
eno
9800	駱昊	   架構師	7800	30000	 5000	 20
9900	王小刀	  程序員  9800	   10000	1200	20
9700	王大錘	  程序員  9800    8000 	600	    20
```

`DataFrame`對象的屬性如下表所示。

| 屬性名         | 說明                                |
| -------------- | ----------------------------------- |
| `at` / `iat`   | 通過標簽獲取`DataFrame`中的單個值。 |
| `columns`      | `DataFrame`對象列的索引             |
| `dtypes`       | `DataFrame`對象每一列的數據類型     |
| `empty`        | `DataFrame`對象是否為空             |
| `loc` / `iloc` | 通過標簽獲取`DataFrame`中的一組值。 |
| `ndim`         | `DataFrame`對象的維度               |
| `shape`        | `DataFrame`對象的形狀（行數和列數） |
| `size`         | `DataFrame`對象中元素的個數         |
| `values`       | `DataFrame`對象的數據對應的二維數組 |

關於`DataFrame`的方法，首先需要了解的是`info()`方法，它可以幫助我們了解`DataFrame`的相關信息，如下所示。

代碼：

```python
emp_df.info()
```

輸出：

```
<class 'pandas.core.frame.DataFrame'>
Int64Index: 14 entries, 1359 to 7800
Data columns (total 6 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   ename   14 non-null     object 
 1   job     14 non-null     object 
 2   mgr     13 non-null     float64
 3   sal     14 non-null     int64  
 4   comm    6 non-null      float64
 5   dno     14 non-null     int64  
dtypes: float64(2), int64(2), object(2)
memory usage: 1.3+ KB
```

如果需要查看`DataFrame`的頭部或尾部的數據，可以使用`head()`或`tail()`方法，這兩個方法的默認參數是`5`，表示獲取`DataFrame`最前面5行或最後面5行的數據，如下所示。

```python
emp_df.head()
```

輸出：

```
        ename    job    mgr    sal    comm  dno
eno						
1359	胡一刀   銷售員	3344   1800  200   30
2056	喬峰	   分析師	 7800   5000  1500	20
3088	李莫愁	  設計師	2056   3500  800   20
3211	張無忌	  程序員	2056   3200  NaN   20
3233	丘處機	  程序員	2056   3400	 NaN   20
```

#### 獲取數據

##### 索引和切片

如果要獲取`DataFrame`的某一列，例如取出上面`emp_df`的`ename`列，可以使用下面的兩種方式。

```python
emp_df.ename
```

或者

```python
emp_df['ename']
```

執行上面的代碼可以發現，我們獲得的是一個`Series`對象。事實上，`DataFrame`對象就是將多個`Series`對象組合到一起的結果。

如果要獲取`DataFrame`的某一行，可以使用整數索引或我們設置的索引，例如取出員工編號為`2056`的員工數據，代碼如下所示。

```python
emp_df.iloc[1]
```

或者

```python
emp_df.loc[2056]
```

通過執行上面的代碼我們發現，單獨取`DataFrame` 的某一行或某一列得到的都是`Series`對象。我們當然也可以通過花式索引來獲取多個行或多個列的數據，花式索引的結果仍然是一個`DataFrame`對象。

獲取多個列：

```python
emp_df[['ename', 'job']]
```

獲取多個行：

```python
emp_df.loc[[2056, 7800, 3344]]
```

如果要獲取或修改`DataFrame` 對象某個單元格的數據，需要同時指定行和列的索引，例如要獲取員工編號為`2056`的員工的職位信息，代碼如下所示。

```python
emp_df['job'][2056]
```

或者

```python
emp_df.loc[2056]['job']
```

或者

```python
emp_df.loc[2056, 'job']
```

我們推薦大家使用第三種做法，因為它只做了一次索引運算。如果要將該員工的職位修改為“架構師”，可以使用下面的代碼。

```python
emp_df.loc[2056, 'job'] = '架構師'
```

當然，我們也可以通過切片操作來獲取多行多列，相信大家一定已經想到了這一點。

```python
emp_df.loc[2056:3344]
```

輸出：

```
        ename    job        mgr      sal     comm    dno
eno
2056	喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3088	李莫愁	   設計師	   2056.0	3500	800.0	20
3211	張無忌	   程序員	   2056.0	3200	NaN     20
3233	丘處機	   程序員	   2056.0	3400	NaN	    20
3244	歐陽鋒	   程序員	   3088.0	3200	NaN     20
3251	張翠山	   程序員	   2056.0	4000	NaN	    20
3344	黃蓉	    銷售主管   7800.0	3000	800.0	30
```

##### 數據篩選

上面我們提到了花式索引，相信大家已經聯想到了布爾索引。跟`ndarray`和`Series`一樣，我們可以通過布爾索引對`DataFrame`對象進行數據篩選，例如我們要從`emp_df`中篩選出月薪超過`3500`的員工，代碼如下所示。

```python
emp_df[emp_df.sal > 3500]
```

輸出：

```
        ename    job        mgr      sal     comm    dno
eno
2056	喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3251	張翠山	   程序員	   2056.0	4000	NaN	    20
5566	宋遠橋	   會計師	   7800.0	4000	1000.0	10
7800	張三豐	   總裁	    NaN      9000	 1200.0	 20
```

當然，我們也可以組合多個條件來進行數據篩選，例如從`emp_df`中篩選出月薪超過`3500`且部門編號為`20`的員工，代碼如下所示。

```python
emp_df[(emp_df.sal > 3500) & (emp_df.dno == 20)]
```

輸出：

```
        ename    job        mgr      sal     comm    dno
eno
2056	喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3251	張翠山	   程序員	   2056.0	4000	NaN	    20
7800	張三豐	   總裁	    NaN      9000	 1200.0	 20
```

除了使用布爾索引，`DataFrame`對象的`query`方法也可以實現數據篩選，`query`方法的參數是一個字符串，它代表了篩選數據使用的表達式，而且更符合 Python 程序員的使用習慣。下面我們使用`query`方法將上面的效果重新實現一遍，代碼如下所示。

```python
emp_df.query('sal > 3500 and dno == 20')
```

#### 重塑數據

有的時候，我們做數據分析需要的原始數據可能並不是來自一個地方，就像上面的例子中，我們從關系型數據庫中讀取了三張表，得到了三個`DataFrame`對象，但實際工作可能需要我們把他們的數據整合到一起。例如：`emp_df`和`emp2_df`其實都是員工的數據，而且數據結構完全一致，我們可以使用`pandas`提供的`concat`函數實現兩個或多個`DataFrame`的數據拼接，代碼如下所示。

```python
all_emp_df = pd.concat([emp_df, emp2_df])
```

輸出：

```
        ename    job        mgr      sal     comm    dno
eno
1359    胡一刀    銷售員	   3344.0	1800	200.0	30
2056    喬峰	    分析師	    7800.0	 5000	 1500.0	 20
3088    李莫愁	   設計師	   2056.0	3500	800.0	20
3211    張無忌	   程序員	   2056.0	3200	NaN     20
3233    丘處機	   程序員	   2056.0	3400	NaN	    20
3244    歐陽鋒	   程序員	   3088.0	3200	NaN     20
3251    張翠山	   程序員	   2056.0	4000	NaN	    20
3344    黃蓉	    銷售主管   7800.0	3000	800.0	30
3577    楊過	    會計	     5566.0	  2200	  NaN	  10
3588    朱九真	   會計	    5566.0	 2500	 NaN	 10
4466    苗人鳳	   銷售員	   3344.0	2500	NaN	    30
5234    郭靖	    出納	     5566.0	  2000	  NaN	  10
5566    宋遠橋	   會計師	   7800.0	4000	1000.0	10
7800    張三豐	   總裁	    NaN      9000	 1200.0	 20
9800    駱昊	    架構師     7800.0	 30000	 5000.0	 20
9900    王小刀	   程序員     9800.0	10000	1200.0	20
9700    王大錘	   程序員     9800.0	8000	600.0	20
```

上面的代碼將兩個代表員工數據的`DataFrame`拼接到了一起，接下來我們使用`merge`函數將員工表和部門表的數據合並到一張表中，代碼如下所示。

先使用`reset_index`方法重新設置`all_emp_df`的索引，這樣`eno` 不再是索引而是一個普通列，`reset_index`方法的`inplace`參數設置為`True`表示，重置索引的操作直接在`all_emp_df`上執行，而不是返回修改後的新對象。

```python
all_emp_df.reset_index(inplace=True)
```

通過`merge`函數合並數據，當然，也可以調用`DataFrame`對象的`merge`方法來達到同樣的效果。

```python
pd.merge(dept_df, all_emp_df, how='inner', on='dno')
```

輸出：

```
    dno dname  dloc eno   ename  job      mgr     sal    comm
0   10	會計部	北京	3577  楊過	會計	   5566.0  2200   NaN
1   10	會計部	北京	3588  朱九真  會計     5566.0  2500   NaN
2   10	會計部	北京	5234  郭靖	出納	   5566.0  2000   NaN
3   10	會計部	北京	5566  宋遠橋  會計師   7800.0	 4000   1000.0
4   20	研發部	成都	2056  喬峰	架構師   7800.0  5000	 1500.0
5   20	研發部	成都	3088  李莫愁  設計師   2056.0	 3500   800.0
6   20	研發部	成都	3211  張無忌  程序員   2056.0	 3200   NaN
7   20	研發部	成都	3233  丘處機  程序員   2056.0	 3400   NaN
8   20	研發部	成都	3244  歐陽鋒  程序員   3088.0	 3200   NaN
9   20	研發部	成都	3251  張翠山  程序員   2056.0	 4000   NaN
10  20	研發部	成都	7800  張三豐  總裁     NaN     9000   1200.0
11  20	研發部	成都	9800  駱昊    架構師   7800.0  30000	 5000.0
12  20	研發部	成都	9900  王小刀  程序員	 9800.0	 10000  1200.0
13  20	研發部	成都	9700  王大錘  程序員	 9800.0	 8000   600.0
14  30	銷售部	重慶	1359  胡一刀  銷售員	 3344.0	 1800   200.0
15  30	銷售部	重慶	3344  黃蓉    銷售主管 7800.0	 3000   800.0
16  30	銷售部	重慶	4466  苗人鳳  銷售員   3344.0	 2500   NaN
```

`merge`函數的一個參數代表合並的左表、第二個參數代表合並的右表，有SQL編程經驗的同學對這兩個詞是不是感覺到非常親切。正如大家猜想的那樣，`DataFrame`對象的合並跟數據庫中的表連接非常類似，所以上面代碼中的`how`代表了合並兩張表的方式，有`left`、`right`、`inner`、`outer`四個選項；而`on`則代表了基於哪個列實現表的合並，相當於 SQL 表連接中的連表條件，如果左右兩表對應的列列名不同，可以用`left_on`和`right_on`參數取代`on`參數分別進行指定。

如果對上面的代碼稍作修改，將`how`參數修改為`left`，大家可以思考一下代碼執行的結果。

```python
pd.merge(dept_df, all_emp_df, how='left', on='dno')
```

運行結果比之前的輸出多出了如下所示的一行，這是因為`left`代表左外連接，也就意味著左表`dept_df`中的數據會被完整的查出來，但是在`all_emp_df`中又沒有編號為`40` 部門的員工，所以對應的位置都被填入了空值。

```
17  40  運維部  天津  NaN  NaN  NaN  NaN  NaN  NaN
```
